{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b43ab41",
   "metadata": {},
   "source": [
    "## Classificador binário para características morfométricas de núcleo/citoplasma de células cervicais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd46ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from math import sqrt\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow \n",
    "from skimage import morphology, measure\n",
    "from skimage.draw import polygon, polygon_perimeter\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "import pyefd\n",
    "from pyefd import elliptic_fourier_descriptors, normalize_efd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# pay attention to capitalization below!\n",
    "from spFSR import SpFSR\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE, BorderlineSMOTE\n",
    "\n",
    "from itertools import cycle\n",
    "from random import randint\n",
    "from random import sample\n",
    "\n",
    "import xgboost as xgb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b5ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bethesda_classes = {'Normal':0, 'ASC-US':1, 'ASC-H':2, 'LSIL':3,'HSIL':4, 'Invasive Carcinoma':5} \n",
    "Bethesda_idx_classes = {0: 'Normal', 1:'ASC-US', 2:'ASC-H', 3:'LSIL',4: 'HSIL', 5:'Invasive Carcinoma'} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1bc67",
   "metadata": {},
   "source": [
    "### Funções para normalizar (todos os dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3690bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normaliza dados\n",
    "def normalize(min, max, value):\n",
    "    return (value-min)/(max - min)\n",
    "\n",
    "def normalize_prop(prop, df):\n",
    "    min = np.min(df[prop].values)\n",
    "    max = np.max(df[prop].values)\n",
    "    return (normalize(min, max, df[prop].values))\n",
    "\n",
    "# Filtra/normaliza dados\n",
    "def normalize_dataset(df, n_efd_coeffs):\n",
    "  dataset = df.copy()\n",
    "   \n",
    "  dataset.areaN = normalize_prop('areaN', df)\n",
    "  dataset.eccenN = normalize_prop('eccenN', df) \n",
    "  dataset.extentN = normalize_prop('extentN', df)\n",
    "  dataset.periN = normalize_prop('periN', df)\n",
    "  dataset.maxAxN = normalize_prop('maxAxN', df)  \n",
    "  dataset.minAxN = normalize_prop('minAxN', df)  \n",
    "  dataset.compacN = normalize_prop('compacN', df)\n",
    "  dataset.circuN = normalize_prop('circuN', df)\n",
    "  dataset.convexN = normalize_prop('convexN', df)\n",
    "  dataset.hAreaN = normalize_prop('hAreaN', df)\n",
    "  dataset.solidN = normalize_prop('solidN', df) \n",
    "  dataset.equidiaN = normalize_prop('equidiaN', df) \n",
    "  dataset.elonN = normalize_prop('elonN', df)\n",
    "  dataset.eN = normalize_prop('eN', df)  \n",
    "  dataset.kN = normalize_prop('kN', df)  \n",
    "  dataset.mrdN = normalize_prop('mrdN', df)  \n",
    "  dataset.ardN = normalize_prop('ardN', df)  \n",
    "  dataset.fdN = normalize_prop('fdN', df)       \n",
    "  efds = ['efdN'+str(i) for i in range(1,(n_efd_coeffs*4 + 1 - 3))]\n",
    "  for efd in efds: \n",
    "      dataset[efd] = normalize_prop(efd, df) \n",
    "    \n",
    "  dataset.areaC = normalize_prop('areaC', df)\n",
    "  dataset.eccenC = normalize_prop('eccenC', df) \n",
    "  dataset.extentC = normalize_prop('extentC', df)\n",
    "  dataset.periC = normalize_prop('periC', df)\n",
    "  dataset.maxAxC = normalize_prop('maxAxC', df)  \n",
    "  dataset.minAxC = normalize_prop('minAxC', df)\n",
    "  dataset.compacC = normalize_prop('compacC', df)\n",
    "  dataset.circuC = normalize_prop('circuC', df)\n",
    "  dataset.convexC = normalize_prop('convexC', df)\n",
    "  dataset.hAreaC = normalize_prop('hAreaC', df)\n",
    "  dataset.solidC = normalize_prop('solidC', df) \n",
    "  dataset.equidiaC = normalize_prop('equidiaC', df) \n",
    "  dataset.elonC = normalize_prop('elonC', df)\n",
    "  dataset.eC = normalize_prop('eC', df)  \n",
    "  dataset.kC = normalize_prop('kC', df)  \n",
    "  dataset.mrdC = normalize_prop('mrdC', df)  \n",
    "  dataset.ardC = normalize_prop('ardC', df)  \n",
    "  dataset.fdC = normalize_prop('fdC', df)       \n",
    "  efds = ['efdC'+str(i) for i in range(1,(n_efd_coeffs*4 + 1 - 3))]\n",
    "  for efd in efds: \n",
    "      dataset[efd] = normalize_prop(efd, df)   \n",
    "\n",
    "  #dataset.nucleus_position = normalize_prop('nucleus_position', df)\n",
    " \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ebbd79",
   "metadata": {},
   "source": [
    " ###  Funções - organiza dados (x, y, ids) e filtra base para diferentes classificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae5b901",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Monta base e retorna 3 dataframes: data (x), target(2,3 e 6 classes), image/cell_id\n",
    "def get_database_data_targe_ids(data_normal, data_ascus, \n",
    "                       data_lsil, data_asch, data_hsil,data_car,\n",
    "                       features_to_fit):\n",
    " \n",
    "    data =  pd.DataFrame(data=np.vstack([\n",
    "                          data_normal.values,\n",
    "                          data_ascus.values,\n",
    "                          data_asch.values,\n",
    "                          data_lsil.values, \n",
    "                          data_hsil.values,\n",
    "                          data_car.values]), \n",
    "                         columns = data_car.columns)\n",
    "    \n",
    "    ## ID's imagens e celulas\n",
    "    image_cells_ids= data[['image_id', 'cell_id']].copy() \n",
    "    \n",
    "    ##Ajusta y(target) para classificação binária, ternária além de bethesda\n",
    "    y = np.array(data['bethesda'].values)\n",
    "    y_bin = np.array(y)\n",
    "    y_ter = np.array(y)\n",
    "        \n",
    "    for i in range(data.shape[0]):\n",
    "         y_bin[i] = 0 if y_bin[i]==0 else 1\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "          if y_ter[i] == 3:  ##Lsil\n",
    "             y_ter[i] = 1\n",
    "          elif (y_ter[i] == 4 or y_ter[i] == 5):  ##HSIl e Car\n",
    "                y_ter[i] = 2\n",
    "                \n",
    "    target = pd.DataFrame(data = np.stack([y_bin,\n",
    "                                           y_ter,\n",
    "                                           y], axis=-1),\n",
    "                          columns = ['binary', 'ternary', 'bethesda'])\n",
    "    \n",
    "    data = data[features_to_fit]      \n",
    "    return data, target, image_cells_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "74e5a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepara dados para tuning de parâmetros\n",
    "## Valores para type: 1 (normal/anormal), 2(baixo/alto grau), 3(ASCUS/LSIL), 4(ASCH/HSIL/CAR)\n",
    "\n",
    "def filter_dataXY(X, y, cls_type):\n",
    "    # X e y devem ser do tipo dataframe \n",
    "    \n",
    "    if cls_type == 1: # (normal/anormal)\n",
    "        return (X, y['binary'])\n",
    "    elif cls_type == 2: # (baixo/alto grau)\n",
    "          lines = filter_lines(y['ternary'], [1,2])\n",
    "          return (X.loc[lines], y['ternary'].loc[lines])  \n",
    "    elif cls_type == 3: # (ASCUS/LSIL)\n",
    "          lines = filter_lines(y['bethesda'], [1,3])\n",
    "          return (X.loc[lines], y['bethesda'].loc[lines])  \n",
    "    else: #(ASCH/HSIL/Car)    \n",
    "          lines = filter_lines(y['bethesda'], [2,4,5])\n",
    "          return (X.loc[lines], y['bethesda'].loc[lines])                           \n",
    "\n",
    "## Filtra linhas\n",
    "def filter_lines(y, cls):\n",
    "   lines = []\n",
    "   for idx, value in zip(y.index, y.values):\n",
    "        if (value in cls):\n",
    "            lines.append(idx)\n",
    "   return lines\n",
    "\n",
    "## Filtra dados para teste do classificador 2 com base nas predições do classificador 1:\n",
    "def filter_Xy_from_cls1_to_cls2(data, target, predics_bin, idx_test):\n",
    "    lines = []\n",
    "    for i in idx_test:\n",
    "        if predics_bin[i] == 1: #Anormal  \n",
    "             lines.append(i)\n",
    "            \n",
    "    X = data.loc[lines]\n",
    "    y = target['ternary'].loc[lines]\n",
    "    return (lines, X, y)\n",
    "\n",
    "## Filtra dados para teste do classificador 3 com base nas predições do classificador 2:\n",
    "def filter_Xy_from_cls1_to_cls3(data, target, predics_ter, idx_test):\n",
    "    lines = []\n",
    "    for i in idx_test:\n",
    "        if predics_ter[i] == 1:  #lesão de baixo grau\n",
    "             lines.append(i)\n",
    "            \n",
    "    X = data.loc[lines]\n",
    "    y = target['bethesda'].loc[lines]\n",
    "    return (lines, X, y)\n",
    "\n",
    "## Filtra dados para teste do classificador 4 com base nas predições do classificador 2:\n",
    "def filter_Xy_from_cls2_to_cls4(data, target, predics_ter, idx_test):\n",
    "    lines = []\n",
    "    for i in idx_test:\n",
    "        if predics_ter[i] == 2:  #lesão de baixo grau\n",
    "             lines.append(i)\n",
    "            \n",
    "    X = data.loc[lines]\n",
    "    y = target['bethesda'].loc[lines]\n",
    "    return (lines, X, y)\n",
    "\n",
    "## Seleciona indices com pred = cls de idx_test          \n",
    "def index_pred_from_class(idx_test, pred_y, cls=0):\n",
    "    idx = []\n",
    "    for i, pred in zip(idx_test, pred_y):\n",
    "        if (pred == cls):\n",
    "            idx.append(i)\n",
    "    return idx\n",
    " \n",
    "## Contabiliza tempo:\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b81cb",
   "metadata": {},
   "source": [
    "### Funções para seleção de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07dc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_features(n_efd_coeffs):\n",
    "   # n_efd_coeffs: número de coefficientes a considerar (série Eliptica de fourier - EFD) para N e C\n",
    "     \n",
    "   feature_labels=['areaN', 'eccenN', 'extentN', 'periN', 'maxAxN', 'minAxN',\n",
    "                   'compacN', 'circuN', 'convexN', 'hAreaN', 'solidN', 'equidiaN', \n",
    "                   'elonN', 'sdnrlN', 'raN', 'riN', 'eN', 'kN', 'mrdN', 'ardN', 'fdN'] \n",
    "   \n",
    "   efdNs = ['efdN'+str(i) for i in range(1, (n_efd_coeffs*4+1 - 3))]  \n",
    "   for name_f in efdNs:\n",
    "       feature_labels.append(name_f) \n",
    "   \n",
    "   aux=['areaC', 'eccenC', 'extentC', 'periC', 'maxAxC', 'minAxC',\n",
    "         'compacC', 'circuC', 'convexC', 'hAreaC', 'solidC', 'equidiaC', \n",
    "          'elonC', 'sdnrlC', 'raC', 'riC', 'eC', 'kC', 'mrdC', 'ardC', 'fdC'] \n",
    "   for name_f in aux:\n",
    "       feature_labels.append(name_f)\n",
    "\n",
    "   efdCs = ['efdC'+str(i) for i in range(1, (n_efd_coeffs*4+1 - 3))]  \n",
    "   for name_f in efdCs:\n",
    "       feature_labels.append(name_f)\n",
    "    \n",
    "   aux = ['ratio_NC', 'ratio_NC_per', 'ratio_NC_hArea', 'nucleus_position']\n",
    "\n",
    "   for name_f in aux:\n",
    "       feature_labels.append(name_f)\n",
    "   return feature_labels   \n",
    "\n",
    "def list_all_EFD_features(n_efd_coeffs):\n",
    "   # n_efd_coeffs: número de coefficientes a considerar (série Eliptica de fourier - EFD) para N e C\n",
    "\n",
    "   feature_labels = ['efdN'+str(i) for i in range(1, (n_efd_coeffs*4+1 - 3))]      \n",
    "   efdCs = ['efdC'+str(i) for i in range(1, (n_efd_coeffs*4+1 - 3))]  \n",
    "   for name_f in efdCs:\n",
    "       feature_labels.append(name_f)\n",
    "   return feature_labels   \n",
    "\n",
    "\n",
    "def list_all_nucleus_features(n_efd_coeffs):\n",
    "   # n_efd_coeffs: número de coefficientes a considerar (série Eliptica de fourier - EFD) para N e C\n",
    "     \n",
    "   feature_labels=['areaN', 'eccenN', 'extentN', 'periN', 'maxAxN', 'minAxN',\n",
    "                   'compacN', 'circuN', 'convexN', 'hAreaN', 'solidN', 'equidiaN', \n",
    "                   'elonN', 'sdnrlN', 'raN', 'riN', 'eN', 'kN', 'mrdN', 'ardN', 'fdN'] \n",
    "   \n",
    "   efdNs = ['efdN'+str(i) for i in range(1, (n_efd_coeffs*4+1 - 3))]  \n",
    "   for name_f in efdNs:\n",
    "       feature_labels.append(name_f) \n",
    "    \n",
    "   #TODO: incluir features abaixo? \n",
    "   #aux = ['ratio_NC', 'ratio_NC_per', 'ratio_NC_hArea', 'nucleus_position']\n",
    "   #for name_f in aux:\n",
    "   #    feature_labels.append(name_f)\n",
    "\n",
    "   return feature_labels   \n",
    "\n",
    "def list_all_cyto_features(n_efd_coeffs):\n",
    "   # n_efd_coeffs: número de coefficientes a considerar (série Eliptica de fourier - EFD) para N e C\n",
    "     \n",
    "   feature_labels =['areaC', 'eccenC', 'extentC', 'periC', 'maxAxC', 'minAxC',\n",
    "         'compacC', 'circuC', 'convexC', 'hAreaC', 'solidC', 'equidiaC', \n",
    "          'elonC', 'sdnrlC', 'raC', 'riC', 'eC', 'kC', 'mrdC', 'ardC', 'fdC'] \n",
    "\n",
    "   efdCs = ['efdC'+str(i) for i in range(1, (n_efd_coeffs*4+1 - 3))]  \n",
    "   for name_f in efdCs:\n",
    "       feature_labels.append(name_f)\n",
    "    \n",
    "   #aux = ['ratio_NC', 'ratio_NC_per', 'ratio_NC_hArea', 'nucleus_position']\n",
    "   #for name_f in aux:\n",
    "   #    feature_labels.append(name_f)\n",
    "    \n",
    "   return feature_labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4457980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 98, 98, 154)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_all_features(20)), len(list_all_nucleus_features(20)), len(list_all_cyto_features(20)), len(list_all_EFD_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab53e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURES SELECTION: \"Simultaneous Perturbation Stochastic Approximation (SPSA) for feature selection and ranking\" \n",
    "# Fonte: An implementation of feature selection and ranking via SPSA based on the article \"K-best feature selection and ranking via stochastic approximation\"(https://www.sciencedirect.com/science/article/abs/pii/S0957417422018826) \n",
    "# Código: https://github.com/akmand/spFSR.git\n",
    "def features_selection_spfsr(X_train, y_train, N_FEATURES = None):        \n",
    "    # pred_type needs to be 'c' for classification and 'r' for regression datasets\n",
    "    sp_engine = SpFSR(x=X_train.values, y=y_train.values, pred_type='c', wrapper=None, scoring='accuracy')\n",
    "    \n",
    "    np.random.seed(999)\n",
    "\n",
    "    if N_FEATURES is not None:\n",
    "        sp_output = sp_engine.run(num_features=N_FEATURES).results    \n",
    "    else:\n",
    "        sp_output = sp_engine.run(num_features=0).results    \n",
    "\n",
    "    fs_indices_spfsr = sp_output.get('selected_features')\n",
    "    best_features_spfsr = np.array(features)[fs_indices_spfsr]\n",
    "    feature_importances_spfsr = sp_output.get('selected_ft_importance')\n",
    "    \n",
    "    return(best_features_spfsr, feature_importances_spfsr)\n",
    "\n",
    "                             \n",
    "### FEATURES SELECTION: método Mutual Information\n",
    "def features_selection_mi(X_train, y_train, list_features, N_FEATURES = 20):    \n",
    "    # All features list:\n",
    "    features = list_features\n",
    "    \n",
    "    aux = [0.0 for i in features]\n",
    "    features_importances = dict(zip(features, aux))\n",
    "  \n",
    "    ## Feature Selection using Mutual Info  \n",
    "    fs_fit_mutual_info = fs.SelectKBest(fs.mutual_info_classif, k=N_FEATURES)\n",
    "    fs_fit_mutual_info.fit_transform(X_train, y_train)\n",
    "\n",
    "    # ordena extrai do maior score para o menor entre as n_features mais importantes\n",
    "    fs_indices_mutual_info = np.argsort(fs_fit_mutual_info.scores_)[::-1][0:N_FEATURES] # extrai do maior score para o menor entre as 10 features mais importantes\n",
    "    best_features_mutual_info = X_train.columns[fs_indices_mutual_info].values\n",
    "    feature_importances_mutual_info = fs_fit_mutual_info.scores_[fs_indices_mutual_info]\n",
    "\n",
    "    best_features_MI = np.asarray(best_features_mutual_info)\n",
    "    feature_importances_MI = np.asarray(feature_importances_mutual_info, dtype = np.float32)    \n",
    "    return (best_features_MI, feature_importances_MI)\n",
    "\n",
    "\n",
    "## Plota gráfico de ganho para features selecionadas: \n",
    "def plot_imp(best_features_1, scores_1, method_name_1,\n",
    "            best_features_2, scores_2, method_name_2):   \n",
    "    \n",
    "    plt.style.use(\"bmh\")\n",
    "    #plt.rcParams.update({'font.size': 12})\n",
    "    fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(15, 7))\n",
    "    axs[0].tick_params(labelsize= 'small')\n",
    "    axs[0].barh(best_features_1, scores_1, color= 'blue', height=0.75)    \n",
    "    axs[0].set(xlim=[min(0, (np.min(scores_1))), max(0.8, np.max(scores_1)+0.1)], xlabel='Score', ylabel='Feature', title= method_name_1 + ' Scores')\n",
    "    axs[1].tick_params(labelsize= 'small')\n",
    "    axs[1].set(xlim=[min(0, np.min(scores_2)), max(0.8, np.max(scores_2)+0.1)], xlabel='Score', ylabel='Feature', title=method_name_2 + ' Scores')\n",
    "    axs[1].barh(best_features_2, scores_2, color= 'green')    \n",
    "    \n",
    "    #fig.suptitle('Feature Selection') \n",
    "    fig.subplots_adjust(left=0.1, right=0.9, wspace=0.3)\n",
    "    plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3b7c0",
   "metadata": {},
   "source": [
    "### Funções tuning/gridsearch (SVM, RF, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301dbe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def grid_search_SVM(model, params, X, y):\n",
    "    grid_search = GridSearchCV(\n",
    "        model, params, scoring= ['accuracy', 'f1_weighted'], refit='f1_weighted'\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    y_pred = grid_search.predict(X)\n",
    "    print(classification_report(y, y_pred))\n",
    "    return (grid_search.best_params_)\n",
    "\n",
    "def grid_search_RF(model, params, X, y):\n",
    "    grid_search = GridSearchCV(model, param_grid = params, \n",
    "        scoring= 'accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    y_pred = grid_search.predict(X)\n",
    "    print(classification_report(y, y_pred))\n",
    "    return (grid_search.best_params_)\n",
    "\n",
    "def grid_search_XGB(model, params, X, y):\n",
    "    folds = 5\n",
    "    param_comb = 150\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(model, param_distributions= params,\n",
    "                        n_iter=param_comb, scoring='accuracy', n_jobs=-1, \n",
    "                        cv=skf.split(X,y), random_state=1001)\n",
    "\n",
    "    start_time = timer(None) # Tempo inicial\n",
    "    random_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    \n",
    "    print('\\n Best estimator:')\n",
    "    print(random_search.best_estimator_)\n",
    "    print('\\n Best score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "    print(random_search.best_score_ )\n",
    "    results = pd.DataFrame(random_search.cv_results_) \n",
    "    \n",
    "    return random_search.best_params_, results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7b87c",
   "metadata": {},
   "source": [
    "### Funções para classificadores e métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d53786fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera modelos \n",
    "def getModel(params, classifier = 'SVM', class_type = 'binary'):\n",
    "    if classifier == 'SVM':\n",
    "          model = SVC(probability = True, random_state=27).set_params(**params)\n",
    "    elif classifier == 'RF':\n",
    "          model = RandomForestClassifier(oob_score=True, random_state=27).set_params(**params)\n",
    "    elif classifier == 'XGBoost':\n",
    "        if class_type == 'binary':\n",
    "            model = xgb.XGBClassifier(learning_rate=0.2, n_estimators=200, objective= 'binary:logistic',\n",
    "                     scale_pos_weight=1, seed=27).set_params(**params)\n",
    "        else:    # multiclass  \n",
    "            model = xgb.XGBClassifier(learning_rate=0.2, n_estimators=200, objective= 'multi:softprob',\n",
    "                     seed=27).set_params(**params) \n",
    "    else:\n",
    "        model = None # 'MLP toDo'    \n",
    "    return model    \n",
    "\n",
    "# Gera modelos \n",
    "def getModel(params, classifier = 'SVM', class_type = 'binary'):\n",
    "    if classifier == 'SVM':\n",
    "          model = SVC(probability = True, random_state=27).set_params(**params)\n",
    "    elif classifier == 'RF':\n",
    "          model = RandomForestClassifier(oob_score=True, random_state=27).set_params(**params)\n",
    "    elif classifier == 'XGBoost':\n",
    "        if class_type == 'binary':\n",
    "            model = xgb.XGBClassifier(learning_rate=0.2, n_estimators=200, objective= 'binary:logistic',\n",
    "                     scale_pos_weight=1, seed=27).set_params(**params)\n",
    "        else:    # multiclass  \n",
    "            model = xgb.XGBClassifier(learning_rate=0.2, n_estimators=200, objective= 'multi:softprob',\n",
    "                     seed=27).set_params(**params) \n",
    "    else:\n",
    "        model = None # 'MLP toDo'    \n",
    "    return model    \n",
    "    \n",
    "## Ajusta modelos com Cross validation nos dados de treino com aumento de dados em cada fold (retorna métrica de treino)\n",
    "def fit_model_old(X, y, model, cls_type= 1, cv=None):\n",
    "    \"\"\"\n",
    "    Cria folds e upsamples dentro de cada fold.\n",
    "    Returns array de métricas de validação\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    if cls_type == 1:  ## normal/anormal\n",
    "            cls = [0,1]\n",
    "            class_type = 'binary'\n",
    "            label = 1\n",
    "    elif cls_type == 2:   ## baixo/alto grau\n",
    "            cls = [1,2]\n",
    "            le.fit(cls)\n",
    "            class_type = 'binary'\n",
    "            label = 2\n",
    "    elif cls_type == 3:  ## asc-us/lsil\n",
    "            cls = [1,3]\n",
    "            le.fit(cls)\n",
    "            class_type = 'binary'\n",
    "            label = 3\n",
    "    else:              ## asch/hsil/car\n",
    "            cls = [2,4,5]\n",
    "            le.fit(cls)\n",
    "            label= None\n",
    "            class_type = 'ternary'\n",
    " \n",
    "    N_SPLITS = 5\n",
    "    if cv is None:\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, random_state=None)\n",
    "\n",
    "    smoter = BorderlineSMOTE(random_state=42)\n",
    "    accs = precs = recs = specs = f1_scores = aucs = np.zeros((N_SPLITS), dtype = np.float64)\n",
    "    for i, (train_fold_index, val_fold_index) in enumerate(cv.split(X, y)):\n",
    " \n",
    "        # Dados de treinamento\n",
    "        X_train_fold, y_train_fold = X[train_fold_index], y[train_fold_index]\n",
    "        # Dados de validação\n",
    "        X_val_fold, y_val_fold = X[val_fold_index], y[val_fold_index]\n",
    "\n",
    "        # Upsample apenas nos dados de treinamento\n",
    "        X_train_fold_upsample, y_train_fold_upsample = smoter.fit_resample(X_train_fold,\n",
    "                                                                           y_train_fold)\n",
    "        ## codifica rótulos em y se classificadores 2, 3 e 4\n",
    "        if (cls_type != 1):  \n",
    "            y_train_fold_upsample = le.transform(y_train_fold_upsample.astype(np.int32))\n",
    "        else:\n",
    "            y_train_fold_upsample = y_train_fold_upsample.astype(np.int32)\n",
    "            \n",
    "        # Ajusta parâmetros:\n",
    "        #if params == None:\n",
    "            ### fazer aqui?\n",
    "        model = model.fit(X_train_fold_upsample, y_train_fold_upsample)            \n",
    "         \n",
    "        # Predição:\n",
    "        pred_y = model.predict(X_val_fold)\n",
    "        \n",
    "        ## decodifica rótulos em y se classificadores tipos 2, 3 e 4:\n",
    "        if (cls_type!= 1):\n",
    "            pred_y = le.inverse_transform(pred_y)\n",
    "            \n",
    "        # Calcula e registra métricas p/ fold:\n",
    "        accs[i] = calc_metric(y_val_fold, pred_y, metric_type='acc', class_type = class_type, pos_label= label, classes=cls)\n",
    "        precs[i] = calc_metric(y_val_fold, pred_y, metric_type='prec', class_type = class_type, pos_label= label, classes=cls)\n",
    "        recs[i] = calc_metric(y_val_fold, pred_y, metric_type='rec', class_type = class_type, pos_label= label, classes=cls)\n",
    "        specs[i] = calc_metric(y_val_fold, pred_y, metric_type='spec', class_type = class_type, pos_label= label, classes=cls)\n",
    "        f1_scores[i] = calc_metric(y_val_fold, pred_y, metric_type='f1_score', class_type = class_type, pos_label= label, classes=cls)\n",
    "       \n",
    "    ## Registra resultados (dataframe):\n",
    "    metrics = {'acc': np.mean(accs), 'prec': np.mean(precs), 'rec': np.mean(recs), \n",
    "                   'spec': np.mean(specs), 'f1_score': np.mean(f1_scores)}      \n",
    "    return metrics, model\n",
    "\n",
    " \n",
    "# Calcula métricas: (vide metrics_type e classifiers_type)\n",
    "def calc_metric(target_test, target_predict, metric_type='acc', class_type ='binary', pos_label=1, classes=[0,1]):   \n",
    "    if (metric_type == 'acc'):\n",
    "        return accuracy_score(target_test, target_predict)\n",
    "    elif (metric_type == 'prec'):\n",
    "         if (class_type == 'binary'):  ## caso classificadores binário\n",
    "            return  precision_score(target_test, target_predict, pos_label= pos_label, zero_division=0)  \n",
    "         else:  ## multiclasses\n",
    "            return precision_score(target_test, target_predict, average='weighted', zero_division=0)\n",
    "    elif (metric_type == 'rec'):\n",
    "        if (class_type == 'binary'):  ## classificadores binários\n",
    "            return recall_score(target_test, target_predict, pos_label= pos_label, zero_division=0)\n",
    "        else:  ## multiclasses\n",
    "            return  recall_score(target_test, target_predict, average ='weighted', zero_division=0)\n",
    "    elif (metric_type == 'spec'):   \n",
    "         if (class_type == 'binary'):  ## classificadores binários\n",
    "            tn, fp, fn, tp = confusion_matrix(target_test, target_predict).ravel()\n",
    "            return tn/(tn + fp)\n",
    "         else:  ##  multiclasses - média aritmética  \n",
    "            spec = 0\n",
    "            for l in classes:\n",
    "                tn, fp, fn, tp = confusion_matrix((np.array(target_test)==l), (np.array(target_predict)==l)).ravel()\n",
    "                spec += tn/(tn + fp)\n",
    "            return spec/len(classes)  \n",
    "    elif (metric_type == 'f1_score'):      \n",
    "         if (class_type == 'binary'):  ## classificadores binários\n",
    "            f1 = f1_score(target_test, target_predict, pos_label= pos_label)\n",
    "            return f1\n",
    "         else:  ## multiclasses\n",
    "            f1 = f1_score(target_test, target_predict, average= 'weighted')\n",
    "            return f1 \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fill_line_metrics_CV(model_name, featur, line_results, metrics, results, class_type='binary'):\n",
    "    line = pd.Series(data = np.array([class_type, model_name, featur,\n",
    "             '{:.4f}'.format(metrics['acc']), '{:.4f}'.format(metrics['prec']),\n",
    "             '{:.4f}'.format(metrics['rec']),'{:.4f}'.format((1- metrics['spec'])), \n",
    "             '{:.4f}'.format(metrics['spec']), '{:.4f}'.format(metrics['f1_score'])], dtype = object), \n",
    "              index=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , \n",
    "                     'Falso Pos', 'Especif', 'F1_measure']) \n",
    "    results.loc[line_results] = line\n",
    "    \n",
    "# Exibe curva ROC para classificadores binários \n",
    "def plot_roc_curve_CV(roc_curve_list, labels_list, title = \"ROC Curve\"):\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"deeppink\", \"navy\", \"darkorange\"])\n",
    "    plt.style.use(\"bmh\")\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "    for i,color in zip(range(len(roc_curve_list)), colors):\n",
    "        ax.plot(\n",
    "            roc_curve_list[i][0],\n",
    "            roc_curve_list[i][1],\n",
    "            color=color,\n",
    "            label=labels_list[i],\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    " \n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        title= title\n",
    "    )\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Gera grafico matriz confusao  \n",
    "def make_confusionMatrixDisplay(test, pred, labels, title):\n",
    "    cm = confusion_matrix(test, pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    return (disp, title)\n",
    "\n",
    "# Exibe 3 matrizes de confusão uma para cada classificador\n",
    "def plot_conf_matrix(preds_to_conf_matrix, lbls=[0,1], disp_lbls=['normal', 'anormal']):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols= 3, figsize=(15,9))\n",
    "\n",
    "    for i,ax in enumerate(axes.flatten()):\n",
    "          ConfusionMatrixDisplay.from_predictions(preds_to_conf_matrix[i][0], preds_to_conf_matrix[i][1], \n",
    "                                    labels= lbls, cmap='Blues', colorbar=False, ax=ax, display_labels=disp_lbls)\n",
    "          ax.title.set_text(preds_to_conf_matrix[i][2])\n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Ajusta modelos com Cross validation nos dados de treino com aumento de dados em cada fold (retorna métrica de treino)\n",
    "def fit_model(X, y, model, cls_type= 1, cv=None):\n",
    "    \"\"\"\n",
    "    Faz upsamples dos dados de teste\n",
    "    Returns array de métricas de treino\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    if cls_type == 1:  ## normal/anormal\n",
    "            cls = [0,1]\n",
    "            class_type = 'binary'\n",
    "            label = 1\n",
    "    elif cls_type == 2:   ## baixo/alto grau\n",
    "            cls = [1,2]\n",
    "            le.fit(cls)\n",
    "            class_type = 'binary'\n",
    "            label = 2\n",
    "    elif cls_type == 3:  ## asc-us/lsil\n",
    "            cls = [1,3]\n",
    "            le.fit(cls)\n",
    "            class_type = 'binary'\n",
    "            label = 3\n",
    "    else:              ## asch/hsil/car\n",
    "            cls = [2,4,5]\n",
    "            le.fit(cls)\n",
    "            label= None\n",
    "            class_type = 'ternary'\n",
    " \n",
    "    smoter = BorderlineSMOTE(random_state=42)\n",
    "    accs = precs = recs = specs = f1_scores = aucs = 0 \n",
    "     \n",
    "    # Upsample apenas nos dados de treinamento\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=45)\n",
    " \n",
    "    X_train_upsample, y_train_upsample = smoter.fit_resample(X_train, y_train)\n",
    "    \n",
    "    ## codifica rótulos em y se classificadores 2, 3 e 4\n",
    "    if (cls_type != 1):  \n",
    "        y_train_upsample = le.transform(y_train_upsample.astype(np.int32))\n",
    "    else:\n",
    "        y_train_upsample = y_train_upsample.astype(np.int32)\n",
    "            \n",
    "    model = model.fit(X_train_upsample, y_train_upsample)            \n",
    "\n",
    "    # Predição:\n",
    "    pred_y = model.predict(X_val)\n",
    "\n",
    "    ## decodifica rótulos em y se classificadores tipos 2, 3 e 4:\n",
    "    if (cls_type!= 1):\n",
    "        pred_y = le.inverse_transform(pred_y)\n",
    "\n",
    "    # Calcula e registra métricas p/ fold:\n",
    "    accs = calc_metric(y_val, pred_y, metric_type='acc', class_type = class_type, pos_label= label, classes=cls)\n",
    "    precs = calc_metric(y_val, pred_y, metric_type='prec', class_type = class_type, pos_label= label, classes=cls)\n",
    "    recs = calc_metric(y_val, pred_y, metric_type='rec', class_type = class_type, pos_label= label, classes=cls)\n",
    "    specs = calc_metric(y_val, pred_y, metric_type='spec', class_type = class_type, pos_label= label, classes=cls)\n",
    "    f1_scores = calc_metric(y_val, pred_y, metric_type='f1_score', class_type = class_type, pos_label= label, classes=cls)\n",
    "       \n",
    "    ## Registra resultados (dataframe):\n",
    "    metrics = {'acc': accs, 'prec': precs, 'rec': recs, 'spec': specs, 'f1_score': f1_scores}      \n",
    "    return metrics, model\n",
    "\n",
    "## Ajusta modelos com Cross validation nos dados de treino com aumento de dados em cada fold (retorna métrica de treino)\n",
    "def fit_model_old(X, y, model, cls_type= 1, cv=None):\n",
    "    \"\"\"\n",
    "    Cria folds e upsamples dentro de cada fold.\n",
    "    Returns array de métricas de validação\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    if cls_type == 1:  ## normal/anormal\n",
    "            cls = [0,1]\n",
    "            class_type = 'binary'\n",
    "            label = 1\n",
    "    elif cls_type == 2:   ## baixo/alto grau\n",
    "            cls = [1,2]\n",
    "            le.fit(cls)\n",
    "            class_type = 'binary'\n",
    "            label = 2\n",
    "    elif cls_type == 3:  ## asc-us/lsil\n",
    "            cls = [1,3]\n",
    "            le.fit(cls)\n",
    "            class_type = 'binary'\n",
    "            label = 3\n",
    "    else:              ## asch/hsil/car\n",
    "            cls = [2,4,5]\n",
    "            le.fit(cls)\n",
    "            label= None\n",
    "            class_type = 'ternary'\n",
    " \n",
    "    N_SPLITS = 5\n",
    "    if cv is None:\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, random_state=None)\n",
    "\n",
    "    smoter = BorderlineSMOTE(random_state=42)\n",
    "    accs = precs = recs = specs = f1_scores = aucs = np.zeros((N_SPLITS), dtype = np.float64)\n",
    "    for i, (train_fold_index, val_fold_index) in enumerate(cv.split(X, y)):\n",
    " \n",
    "        # Dados de treinamento\n",
    "        X_train_fold, y_train_fold = X[train_fold_index], y[train_fold_index]\n",
    "        # Dados de validação\n",
    "        X_val_fold, y_val_fold = X[val_fold_index], y[val_fold_index]\n",
    "\n",
    "        # Upsample apenas nos dados de treinamento\n",
    "        X_train_fold_upsample, y_train_fold_upsample = smoter.fit_resample(X_train_fold,\n",
    "                                                                           y_train_fold)\n",
    "        ## codifica rótulos em y se classificadores 2, 3 e 4\n",
    "        if (cls_type != 1):  \n",
    "            y_train_fold_upsample = le.transform(y_train_fold_upsample.astype(np.int32))\n",
    "        else:\n",
    "            y_train_fold_upsample = y_train_fold_upsample.astype(np.int32)\n",
    "            \n",
    "        # Ajusta parâmetros:\n",
    "        #if params == None:\n",
    "            ### fazer aqui?\n",
    "        model = model.fit(X_train_fold_upsample, y_train_fold_upsample)            \n",
    "         \n",
    "        # Predição:\n",
    "        pred_y = model.predict(X_val_fold)\n",
    "        \n",
    "        ## decodifica rótulos em y se classificadores tipos 2, 3 e 4:\n",
    "        if (cls_type!= 1):\n",
    "            pred_y = le.inverse_transform(pred_y)\n",
    "            \n",
    "        # Calcula e registra métricas p/ fold:\n",
    "        accs[i] = calc_metric(y_val_fold, pred_y, metric_type='acc', class_type = class_type, pos_label= label, classes=cls)\n",
    "        precs[i] = calc_metric(y_val_fold, pred_y, metric_type='prec', class_type = class_type, pos_label= label, classes=cls)\n",
    "        recs[i] = calc_metric(y_val_fold, pred_y, metric_type='rec', class_type = class_type, pos_label= label, classes=cls)\n",
    "        specs[i] = calc_metric(y_val_fold, pred_y, metric_type='spec', class_type = class_type, pos_label= label, classes=cls)\n",
    "        f1_scores[i] = calc_metric(y_val_fold, pred_y, metric_type='f1_score', class_type = class_type, pos_label= label, classes=cls)\n",
    "       \n",
    "    ## Registra resultados (dataframe):\n",
    "    metrics = {'acc': np.mean(accs), 'prec': np.mean(precs), 'rec': np.mean(recs), \n",
    "                   'spec': np.mean(specs), 'f1_score': np.mean(f1_scores)}      \n",
    "    return metrics, model\n",
    "\n",
    " \n",
    "# Calcula métricas: (vide metrics_type e classifiers_type)\n",
    "def calc_metric(target_test, target_predict, metric_type='acc', class_type ='binary', pos_label=1, classes=[0,1]):   \n",
    "    if (metric_type == 'acc'):\n",
    "        return accuracy_score(target_test, target_predict)\n",
    "    elif (metric_type == 'prec'):\n",
    "         if (class_type == 'binary'):  ## caso classificadores binário\n",
    "            return  precision_score(target_test, target_predict, pos_label= pos_label, zero_division=0)  \n",
    "         else:  ## multiclasses\n",
    "            return precision_score(target_test, target_predict, average='weighted', zero_division=0)\n",
    "    elif (metric_type == 'rec'):\n",
    "        if (class_type == 'binary'):  ## classificadores binários\n",
    "            return recall_score(target_test, target_predict, pos_label= pos_label, zero_division=0)\n",
    "        else:  ## multiclasses\n",
    "            return  recall_score(target_test, target_predict, average ='weighted', zero_division=0)\n",
    "    elif (metric_type == 'spec'):   \n",
    "         if (class_type == 'binary'):  ## classificadores binários\n",
    "            tn, fp, fn, tp = confusion_matrix(target_test, target_predict).ravel()\n",
    "            return tn/(tn + fp)\n",
    "         else:  ##  multiclasses - média aritmética  \n",
    "            spec = 0\n",
    "            for l in classes:\n",
    "                tn, fp, fn, tp = confusion_matrix((np.array(target_test)==l), (np.array(target_predict)==l)).ravel()\n",
    "                spec += tn/(tn + fp)\n",
    "            return spec/len(classes)  \n",
    "    elif (metric_type == 'f1_score'):      \n",
    "         if (class_type == 'binary'):  ## classificadores binários\n",
    "            f1 = f1_score(target_test, target_predict, pos_label= pos_label)\n",
    "            return f1\n",
    "         else:  ## multiclasses\n",
    "            f1 = f1_score(target_test, target_predict, average= 'weighted')\n",
    "            return f1 \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fill_line_metrics_CV(model_name, featur, line_results, metrics, results, class_type='binary'):\n",
    "    line = pd.Series(data = np.array([class_type, model_name, featur,\n",
    "             '{:.4f}'.format(metrics['acc']), '{:.4f}'.format(metrics['prec']),\n",
    "             '{:.4f}'.format(metrics['rec']),'{:.4f}'.format((1- metrics['spec'])), \n",
    "             '{:.4f}'.format(metrics['spec']), '{:.4f}'.format(metrics['f1_score'])], dtype = object), \n",
    "              index=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , \n",
    "                     'Falso Pos', 'Especif', 'F1_measure']) \n",
    "    results.loc[line_results] = line\n",
    "    \n",
    "# Exibe curva ROC para classificadores binários \n",
    "def plot_roc_curve_CV(roc_curve_list, labels_list, title = \"ROC Curve\"):\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"deeppink\", \"navy\", \"darkorange\"])\n",
    "    plt.style.use(\"bmh\")\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "    for i,color in zip(range(len(roc_curve_list)), colors):\n",
    "        ax.plot(\n",
    "            roc_curve_list[i][0],\n",
    "            roc_curve_list[i][1],\n",
    "            color=color,\n",
    "            label=labels_list[i],\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    " \n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        title= title\n",
    "    )\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Gera grafico matriz confusao  \n",
    "def make_confusionMatrixDisplay(test, pred, labels, title):\n",
    "    cm = confusion_matrix(test, pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    return (disp, title)\n",
    "\n",
    "# Exibe 3 matrizes de confusão uma para cada classificador\n",
    "def plot_conf_matrix(preds_to_conf_matrix, lbls=[0,1], disp_lbls=['normal', 'anormal']):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols= 3, figsize=(15,9))\n",
    "\n",
    "    for i,ax in enumerate(axes.flatten()):\n",
    "          ConfusionMatrixDisplay.from_predictions(preds_to_conf_matrix[i][0], preds_to_conf_matrix[i][1], \n",
    "                                    labels= lbls, cmap='Blues', colorbar=False, ax=ax, display_labels=disp_lbls)\n",
    "          ax.title.set_text(preds_to_conf_matrix[i][2])\n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "1f69cea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['binary'].values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f815eb",
   "metadata": {},
   "source": [
    "### Lê arquivo (features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1f00307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EFD_COEFFS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8d2400f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataCRIC.csv', sep='|', header=0)\n",
    "df = normalize_dataset(df, n_efd_coeffs= N_EFD_COEFFS)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a5c0dc99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>areaN</th>\n",
       "      <th>eccenN</th>\n",
       "      <th>extentN</th>\n",
       "      <th>periN</th>\n",
       "      <th>maxAxN</th>\n",
       "      <th>minAxN</th>\n",
       "      <th>compacN</th>\n",
       "      <th>circuN</th>\n",
       "      <th>...</th>\n",
       "      <th>efdC73</th>\n",
       "      <th>efdC74</th>\n",
       "      <th>efdC75</th>\n",
       "      <th>efdC76</th>\n",
       "      <th>efdC77</th>\n",
       "      <th>ratio_NC</th>\n",
       "      <th>ratio_NC_per</th>\n",
       "      <th>ratio_NC_hArea</th>\n",
       "      <th>nucleus_position</th>\n",
       "      <th>bethesda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14796.0</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.606414</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>0.031326</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>0.083827</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>0.863522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156532</td>\n",
       "      <td>0.321490</td>\n",
       "      <td>0.859931</td>\n",
       "      <td>0.382225</td>\n",
       "      <td>0.302311</td>\n",
       "      <td>0.017236</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.099098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.541484</td>\n",
       "      <td>0.808102</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>0.039493</td>\n",
       "      <td>0.095649</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150931</td>\n",
       "      <td>0.317850</td>\n",
       "      <td>0.859539</td>\n",
       "      <td>0.369221</td>\n",
       "      <td>0.299938</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.089517</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.121456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14798.0</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.313794</td>\n",
       "      <td>0.884418</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.097062</td>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.890378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153458</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.861978</td>\n",
       "      <td>0.367980</td>\n",
       "      <td>0.302076</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.073961</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.043773</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14799.0</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.489270</td>\n",
       "      <td>0.778201</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.103428</td>\n",
       "      <td>0.021001</td>\n",
       "      <td>0.879403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.319562</td>\n",
       "      <td>0.860312</td>\n",
       "      <td>0.382943</td>\n",
       "      <td>0.303682</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>0.154784</td>\n",
       "      <td>0.027752</td>\n",
       "      <td>0.128927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14801.0</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>0.036826</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.106376</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.861871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147193</td>\n",
       "      <td>0.314554</td>\n",
       "      <td>0.860292</td>\n",
       "      <td>0.359672</td>\n",
       "      <td>0.300094</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.129992</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>0.069245</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>399.0</td>\n",
       "      <td>11539.0</td>\n",
       "      <td>0.028927</td>\n",
       "      <td>0.838629</td>\n",
       "      <td>0.579720</td>\n",
       "      <td>0.094256</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.118369</td>\n",
       "      <td>0.041270</td>\n",
       "      <td>0.784196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152113</td>\n",
       "      <td>0.318217</td>\n",
       "      <td>0.859606</td>\n",
       "      <td>0.370535</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.206211</td>\n",
       "      <td>0.149094</td>\n",
       "      <td>0.085315</td>\n",
       "      <td>1.943974</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>399.0</td>\n",
       "      <td>11540.0</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.874227</td>\n",
       "      <td>0.645532</td>\n",
       "      <td>0.094611</td>\n",
       "      <td>0.135676</td>\n",
       "      <td>0.100778</td>\n",
       "      <td>0.064959</td>\n",
       "      <td>0.692461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150010</td>\n",
       "      <td>0.322108</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.375599</td>\n",
       "      <td>0.300755</td>\n",
       "      <td>0.245537</td>\n",
       "      <td>0.247086</td>\n",
       "      <td>0.136756</td>\n",
       "      <td>0.916374</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>400.0</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>0.017031</td>\n",
       "      <td>0.910741</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.092280</td>\n",
       "      <td>0.136377</td>\n",
       "      <td>0.078990</td>\n",
       "      <td>0.131860</td>\n",
       "      <td>0.507358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>0.319972</td>\n",
       "      <td>0.860379</td>\n",
       "      <td>0.372458</td>\n",
       "      <td>0.303245</td>\n",
       "      <td>0.191508</td>\n",
       "      <td>0.471092</td>\n",
       "      <td>0.188343</td>\n",
       "      <td>0.326252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>400.0</td>\n",
       "      <td>11536.0</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.949322</td>\n",
       "      <td>0.528816</td>\n",
       "      <td>0.105709</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>0.065965</td>\n",
       "      <td>0.137720</td>\n",
       "      <td>0.494794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151898</td>\n",
       "      <td>0.320620</td>\n",
       "      <td>0.859608</td>\n",
       "      <td>0.370771</td>\n",
       "      <td>0.299599</td>\n",
       "      <td>0.111823</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>0.023058</td>\n",
       "      <td>3.177247</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>400.0</td>\n",
       "      <td>11537.0</td>\n",
       "      <td>0.025076</td>\n",
       "      <td>0.822746</td>\n",
       "      <td>0.749691</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>0.120781</td>\n",
       "      <td>0.114052</td>\n",
       "      <td>0.055801</td>\n",
       "      <td>0.725789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143373</td>\n",
       "      <td>0.318753</td>\n",
       "      <td>0.868085</td>\n",
       "      <td>0.362569</td>\n",
       "      <td>0.279162</td>\n",
       "      <td>0.448090</td>\n",
       "      <td>0.346307</td>\n",
       "      <td>0.181780</td>\n",
       "      <td>0.653692</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3233 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  cell_id     areaN    eccenN   extentN     periN    maxAxN  \\\n",
       "0          1.0  14796.0  0.007403  0.606414  0.842276  0.031326  0.036711   \n",
       "1          1.0  14797.0  0.009371  0.541484  0.808102  0.035945  0.039493   \n",
       "2          1.0  14798.0  0.007275  0.313794  0.884418  0.029457  0.025365   \n",
       "3          1.0  14799.0  0.010570  0.489270  0.778201  0.040199  0.040900   \n",
       "4          1.0  14801.0  0.009115  0.296366  0.842276  0.036826  0.031283   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "3228     399.0  11539.0  0.028927  0.838629  0.579720  0.094256  0.134656   \n",
       "3229     399.0  11540.0  0.025333  0.874227  0.645532  0.094611  0.135676   \n",
       "3230     400.0  11535.0  0.017031  0.910741  0.390863  0.092280  0.136377   \n",
       "3231     400.0  11536.0  0.020797  0.949322  0.528816  0.105709  0.169029   \n",
       "3232     400.0  11537.0  0.025076  0.822746  0.749691  0.090669  0.120781   \n",
       "\n",
       "        minAxN   compacN    circuN  ...    efdC73    efdC74    efdC75  \\\n",
       "0     0.083827  0.024126  0.863522  ...  0.156532  0.321490  0.859931   \n",
       "1     0.095649  0.018763  0.891071  ...  0.150931  0.317850  0.859539   \n",
       "2     0.097062  0.018895  0.890378  ...  0.153458  0.315454  0.861978   \n",
       "3     0.103428  0.021001  0.879403  ...  0.157254  0.319562  0.860312   \n",
       "4     0.106376  0.024456  0.861871  ...  0.147193  0.314554  0.860292   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3228  0.118369  0.041270  0.784196  ...  0.152113  0.318217  0.859606   \n",
       "3229  0.100778  0.064959  0.692461  ...  0.150010  0.322108  0.859366   \n",
       "3230  0.078990  0.131860  0.507358  ...  0.153944  0.319972  0.860379   \n",
       "3231  0.065965  0.137720  0.494794  ...  0.151898  0.320620  0.859608   \n",
       "3232  0.114052  0.055801  0.725789  ...  0.143373  0.318753  0.868085   \n",
       "\n",
       "        efdC76    efdC77  ratio_NC  ratio_NC_per  ratio_NC_hArea  \\\n",
       "0     0.382225  0.302311  0.017236      0.115646        0.016730   \n",
       "1     0.369221  0.299938  0.010656      0.089517        0.010168   \n",
       "2     0.367980  0.302076  0.007400      0.073961        0.006897   \n",
       "3     0.382943  0.303682  0.028309      0.154784        0.027752   \n",
       "4     0.359672  0.300094  0.021569      0.129992        0.020738   \n",
       "...        ...       ...       ...           ...             ...   \n",
       "3228  0.370535  0.299400  0.206211      0.149094        0.085315   \n",
       "3229  0.375599  0.300755  0.245537      0.247086        0.136756   \n",
       "3230  0.372458  0.303245  0.191508      0.471092        0.188343   \n",
       "3231  0.370771  0.299599  0.111823      0.078186        0.023058   \n",
       "3232  0.362569  0.279162  0.448090      0.346307        0.181780   \n",
       "\n",
       "      nucleus_position  bethesda  \n",
       "0             0.099098       0.0  \n",
       "1             0.121456       0.0  \n",
       "2             0.043773       0.0  \n",
       "3             0.128927       0.0  \n",
       "4             0.069245       0.0  \n",
       "...                ...       ...  \n",
       "3228          1.943974       5.0  \n",
       "3229          0.916374       5.0  \n",
       "3230          0.326252       5.0  \n",
       "3231          3.177247       5.0  \n",
       "3232          0.653692       5.0  \n",
       "\n",
       "[3233 rows x 203 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "581d6797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Totais por classe --- \n",
      "Normal...:  862\n",
      "ASC-Us...:  286\n",
      "ASC-H....:  536\n",
      "LSIL.....:  598\n",
      "HSIL.....:  874\n",
      "Carcinoma:  77\n"
     ]
    }
   ],
   "source": [
    "# Separa dados por classe de maneira balanceada:\n",
    "data_normal = df[df['bethesda'] == 0].copy()\n",
    "data_normal.set_index((i for i in range(data_normal.shape[0])), inplace=True)\n",
    "\n",
    "data_ascus = df[df['bethesda'] == 1].copy()\n",
    "data_ascus.set_index((i for i in range(data_ascus.shape[0])), inplace=True)\n",
    "\n",
    "data_asch = df[df['bethesda'] == 2].copy()\n",
    "data_asch.set_index((i for i in range(data_asch.shape[0])), inplace=True)\n",
    "\n",
    "data_lsil = df[df['bethesda'] == 3].copy()\n",
    "data_lsil.set_index((i for i in range(data_lsil.shape[0])), inplace=True)\n",
    "\n",
    "data_hsil = df[df['bethesda'] == 4].copy()\n",
    "data_hsil.set_index((i for i in range(data_hsil.shape[0])), inplace=True)\n",
    "\n",
    "data_car = df[df['bethesda'] == 5].copy()\n",
    "data_car.set_index((i for i in range(data_car.shape[0])), inplace=True)\n",
    "\n",
    "print(\"--- Totais por classe --- \")               \n",
    "print(\"Normal...: \", data_normal.values.shape[0])               \n",
    "print(\"ASC-Us...: \", data_ascus.values.shape[0])               \n",
    "print(\"ASC-H....: \", data_asch.values.shape[0])               \n",
    "print(\"LSIL.....: \", data_lsil.values.shape[0])               \n",
    "print(\"HSIL.....: \", data_hsil.values.shape[0])               \n",
    "print(\"Carcinoma: \", data_car.values.shape[0]) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3e8af",
   "metadata": {},
   "source": [
    "#### Gera dataframes: dados (data), classes (target) e Ids (image/cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "56929844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monta base (data, target, image/cells ids)\n",
    "data, target, image_cells_ids= get_database_data_targe_ids(data_normal, data_ascus, \n",
    "                       data_lsil, data_asch, data_hsil,data_car,\n",
    "                       list_all_features(N_EFD_COEFFS))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e76266",
   "metadata": {},
   "source": [
    "#### Tuning de parâmetros (Classificador) \n",
    "Feito apenas uma vez com um subconjunto dos dados e para cada um dos métodos (SVM, RF e XGBOOST). \n",
    "\n",
    "Conjunto de dados para tuning:\n",
    "\n",
    "   X: merge de todas as features selecionadas para o classificador hierarquico (classificadores 1,2,3, e 4) \n",
    "  \n",
    "   y: rótulos das 6 classes Bethesda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "26dc6716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1.0: 44, 2.0: 107, 0.0: 172, 3.0: 127, 5.0: 13, 4.0: 184}),\n",
       " Counter({2.0: 212, 4.0: 363, 1.0: 118, 0.0: 336, 3.0: 228, 5.0: 36}))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separa dados para treino/validação e teste:\n",
    "(X_train, X_test, y_train, y_test, image_cells_ids_train, image_cells_ids_test) = train_test_split(data, target, image_cells_ids, test_size=0.2, random_state=45)\n",
    "\n",
    "#Separa dados para tuning de parâmetros dos modelos:\n",
    "_, X_train_tuning, _, y_train_tuning = train_test_split(X_train, y_train, test_size=0.5, random_state=45)\n",
    "Counter(y_test['bethesda'].values),  Counter(y_train_tuning['bethesda'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_features_spfsr_1, feature_importances_spfsr_1 = features_selection_spfsr(*filter_dataXY(X_train, y_train, cls_type=1), N_FEATURES = None)\n",
    "#best_features_spfsr_2, feature_importances_spfsr_2 = features_selection_spfsr(*filter_dataXY(X_train, y_train, cls_type=2), N_FEATURES = None)\n",
    "#best_features_spfsr_3, feature_importances_spfsr_3 = features_selection_spfsr(*filter_dataXY(X_train, y_train, cls_type=3), N_FEATURES = None)\n",
    "#best_features_spfsr_4, feature_importances_spfsr_4 = features_selection_spfsr(*filter_dataXY(X_train, y_train, cls_type=4), N_FEATURES = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c81bee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features_sel = list(set(best_features_spfsr_1.tolist() + best_features_spfsr_2.tolist() +\n",
    "#                        best_features_spfsr_3.tolist() + best_features_spfsr_4.tolist()))\n",
    "#len(features_sel), #features_sel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2a044be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]},\n",
    "    {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]},\n",
    "    {\"kernel\": [\"poly\"], \"degree\":[2,3,4], \"gamma\": [1e-3, 1e-4], \"coef0\":[2e-1, 2e-2] , \"C\": [1, 10, 100, 1000]},\n",
    "]\n",
    "#svm_param =  grid_search_SVM(SVC(), svm_params, X_train[features_sel], y_train['bethesda'])\n",
    "#print('Best svm params: ', svm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "07eb6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'n_estimators': [10, 50, 100, 150]\n",
    "            }\n",
    "#rf_param = grid_search_RF(RandomForestClassifier(random_state=0),\n",
    "#                             rf_params, X_train[features_sel], y_train['bethesda'])\n",
    "#print('Best Random Forest params: ', rf_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ef98f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "        'min_child_weight': [1, 5, 7, 10],\n",
    "        'gamma': [0, 0.3, 0.5, 1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 6, 7]\n",
    "        }\n",
    "\n",
    "\n",
    "#xgb_param, result = grid_search_XGB(xgb.XGBClassifier(learning_rate=0.2, \n",
    "#                                               n_estimators=200, objective='multi:softprob'),\n",
    "#                                    xgb_params, X_train[features_sel], y_train['bethesda'])\n",
    "#print('Best XGBoost params: ', xgb_param)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e02587fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param =  {'C': 100, 'kernel': 'linear'}\n",
    "rf_param = {'max_depth': 7, 'min_samples_split': 5, 'n_estimators': 100}\n",
    "xgb_param = {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "26b7c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº total de de features: 200\n"
     ]
    }
   ],
   "source": [
    "classifiers = ['SVM', 'RF', 'XGBoost']\n",
    "params = [svm_param, rf_param, xgb_param]\n",
    "features = list_all_features(N_EFD_COEFFS)\n",
    "print(f'Nº total de de features: {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6ca7f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna mapa para contabilizar as predições para cada amostra em cada classe\n",
    "def def_map_preds_y(y_test, cls_type):\n",
    "    if cls_type == 1:  ## normal/anormal\n",
    "            cls = [0,1]\n",
    "            map_pred = {0: 0, 1:0} \n",
    "    elif cls_type == 2:   ## baixo/alto grau\n",
    "            cls = [1,2]\n",
    "            map_pred = {1: 0, 2:0} \n",
    "    elif cls_type == 3:  ## asc-us/lsil\n",
    "            cls = [1,3]\n",
    "            map_pred = {1: 0, 3:0} \n",
    "    else:   ## asch/hsil/car\n",
    "            cls = [2,4,5]\n",
    "            map_pred = {2: 0, 4:0, 5:0}\n",
    "\n",
    "    map_preds = np.empty((y_test.shape[0]), dtype= object)        \n",
    "    for i in range(y_test.shape[0]):   \n",
    "           map_preds[i] = map_pred.copy()\n",
    "    return map_preds  \n",
    "\n",
    "# Registra predições do conjunto de teste:\n",
    "def set_map_preds_y(map_preds, y_pred, cls_type):\n",
    "    if cls_type == 1:    ## normal/anormal\n",
    "            cls = [0,1]\n",
    "    elif cls_type == 2:   ## baixo/alto grau\n",
    "            cls = [1,2]\n",
    "    elif cls_type == 3:   ## asc-us/lsil\n",
    "            cls = [1,3]\n",
    "    else:   ## asch/hsil/car\n",
    "            cls = [2,4,5]\n",
    "    for i, pred in enumerate(y_pred):\n",
    "        if pred in cls:\n",
    "           map_preds[i][pred]= map_preds[i][pred] + 1 \n",
    "        else:\n",
    "            print(\"**Predição de outra classe \", pred, ' tipo classificado: ', cls_type)\n",
    "\n",
    "# Define predições para o conjunto de teste, considerando a classe mais votada:\n",
    "def finalize_preds_y(map_preds, cls_type):\n",
    "    preds = np.zeros(map_preds.shape[0])\n",
    "    if cls_type == 1:    ## normal/anormal\n",
    "          cls = [0,1]\n",
    "    elif cls_type == 2:   ## baixo/alto grau\n",
    "            cls = [1,2]\n",
    "    elif cls_type == 3:   ## asc-us/lsil\n",
    "            cls = [1,3]\n",
    "    else:   ## asch/hsil/car\n",
    "            cls = [2,4,5]\n",
    "            \n",
    "    if cls_type != 4:\n",
    "        for i, map_pred in enumerate(map_preds):    \n",
    "               if (map_pred[cls[0]] > map_pred[cls[1]]):\n",
    "                    preds[i] = cls[0] \n",
    "               elif (map_pred[cls[0]] < map_pred[cls[1]]):  \n",
    "                    preds[i] = cls[1]\n",
    "               else:  # Não houve classe majoritária \n",
    "                    preds[i] = -1  \n",
    "    else:  ## classificador 4 (ternário)\n",
    "        for i, map_pred in enumerate(map_preds):    \n",
    "               if ((map_pred[cls[0]] > map_pred[cls[1]]) and (map_pred[cls[0]] > map_pred[cls[2]])):\n",
    "                   preds[i] = cls[0] \n",
    "               elif (map_pred[cls[1]] > map_pred[cls[2]]):\n",
    "                    preds[i] = cls[1]\n",
    "               elif (map_pred[cls[1]] < map_pred[cls[2]]):\n",
    "                    preds[i] = cls[2]\n",
    "               else:  # Não houve classe majoritária\n",
    "                    preds[i] = -1       \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b91d5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Aplica seleção de features (executada em separado): classificadores (1, 2, 3, 4)\n",
    "best_features_spfsr_1 =  ['ratio_NC','ratio_NC_per', 'eN', 'ratio_NC_hArea', 'ardN']\n",
    "best_features_MI_1 =  ['ratio_NC', 'ratio_NC_per', 'ratio_NC_hArea', 'mrdN', 'eN', 'maxAxN', 'periN',\n",
    "                       'ardN', 'hAreaN', 'equidiaN', 'areaN', 'fdN', 'compacC', 'circuC', 'riN', 'areaC',\n",
    "                       'periC', 'hAreaC', 'minAxC', 'maxAxC', 'ardC', 'fdC', 'mrdC', 'equidiaC', 'eC',\n",
    "                       'circuN', 'compacN', 'riC', 'minAxN', 'convexN']\n",
    "best_features_spfsr_2 =  ['areaC', 'fdC', 'eC', 'ratio_NC', 'ratio_NC_hArea', 'maxAxC', 'equidiaC', 'mrdC',\n",
    "                          'compacC', 'periC']\n",
    "best_features_MI_2 =  ['areaC', 'equidiaC', 'fdC', 'hAreaC', 'ardC', 'periC', 'ratio_NC_hArea', 'ratio_NC',\n",
    "                         'mrdC', 'maxAxC', 'eC', 'ratio_NC_per', 'riC', 'minAxC', 'circuC', 'compacC',\n",
    "                         'equidiaN', 'areaN', 'fdN', 'hAreaN', 'riN', 'periN', 'minAxN','nucleus_position',\n",
    "                         'ardN', 'solidC', 'maxAxN', 'extentC', 'mrdN', 'eN']  \n",
    "best_features_spfsr_3 =  ['solidN', 'nucleus_position', 'efdC55', 'efdN41', 'compacN', 'periC', 'efdN40', 'eccenN',\n",
    "                         'extentC', 'efdN63', 'efdN3', 'efdN43', 'efdN38', 'efdC17', 'efdC54','efdN48', 'efdN69',\n",
    "                         'circuN', 'efdN9', 'efdC71', 'efdN15', 'efdN58', 'elonC', 'efdN76', 'efdN19',\n",
    "                         'efdN22', 'efdN14', 'efdC8', 'efdC4', 'efdC63']\n",
    "best_features_MI_3 = ['efdC31', 'efdC39', 'efdC33', 'efdN76', 'efdN12', 'efdN39', 'efdC41', 'efdC14', 'efdC51',\n",
    "                      'mrdN', 'efdC63', 'efdC4', 'efdN33', 'extentN', 'minAxN', 'efdN55', 'efdC44', 'efdN15',\n",
    "                      'efdN2', 'fdC', 'efdN25', 'efdC1', 'efdC66', 'efdC34','circuC', 'efdN65', 'efdN62',\n",
    "                      'efdC18', 'efdN74', 'efdC40']\n",
    "best_features_spfsr_4 =  ['ratio_NC_per', 'ratio_NC', 'ratio_NC_hArea', 'areaC', 'efdN51', 'minAxC', 'efdC38',\n",
    "                          'efdC18', 'efdN27', 'efdN14'] \n",
    "best_features_MI_4 =  ['ratio_NC', 'ratio_NC_hArea', 'ratio_NC_per', 'areaC', 'periC', 'mrdC', 'eC', 'compacC',\n",
    "                       'solidC', 'circuC', 'ardC', 'extentC', 'maxAxC', 'eccenC', 'nucleus_position', 'raC',\n",
    "                       'riC', 'hAreaC', 'convexC', 'convexN', 'efdC62', 'efdC52', 'efdC2', 'extentN', 'efdC32',\n",
    "                       'efdC74', 'efdC33', 'efdC6', 'raN', 'efdC54']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "513173bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_features_MI_4), len(best_features_spfsr_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da6443",
   "metadata": {},
   "source": [
    "## Experiment nº1:   features (nucleus + cytoplasm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e110ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_desc = \"Selected features to nucleus and cytoplasm\"\n",
    "N_FEATURES = 30\n",
    "N_ITER = 10\n",
    " \n",
    "accs = precs = recs = specs = f1_scores = aucs = np.zeros((3))\n",
    "\n",
    "labels_list_bin = [] \n",
    "roc_curve_list_bin = []\n",
    "\n",
    "preds_to_conf_matrix_bin= []\n",
    "preds_to_conf_matrix_ter= []\n",
    "preds_to_conf_matrix_bet= []\n",
    "\n",
    "results_bin = pd.DataFrame(columns=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , 'Falso Pos', 'Especif', 'F1_measure'])\n",
    "results_ter = pd.DataFrame(columns=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , 'Falso Pos', 'Especif', 'F1_measure'])\n",
    "results_bet = pd.DataFrame(columns=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , 'Falso Pos', 'Especif', 'F1_measure'])\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "39014f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara array para registro de predições (classific. binário, ternário e bethesda) separado por algoritmos:\n",
    "preds_bin = np.ones((data.shape[0],3))*-1\n",
    "probs_bin = np.zeros((data.shape[0],3,2))\n",
    " \n",
    "preds_ter = np.ones((data.shape[0],3))*-1\n",
    "probs_ter = np.zeros((data.shape[0],3,2))\n",
    "\n",
    "preds_bet = np.ones((data.shape[0],3))*-1\n",
    "probs_bet = np.zeros((data.shape[0],3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "88d65669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;background-color: white;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_2 = preprocessing.LabelEncoder()\n",
    "le_2.fit([1,2])\n",
    "le_3 = preprocessing.LabelEncoder()\n",
    "le_3.fit([1,3])\n",
    "le_4 = preprocessing.LabelEncoder()\n",
    "le_4.fit([2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração número:  0\n",
      "metricas : 0 {'acc': 0.6417910447761194, 'prec': 0.6937547242737708, 'rec': 0.6417910447761194, 'spec': 0.8030355774493705, 'f1_score': 0.6462186674284082}\n",
      "metricas : 1 {'acc': 0.6343283582089553, 'prec': 0.6586709310589908, 'rec': 0.6343283582089553, 'spec': 0.7818193760262725, 'f1_score': 0.6375551818372924}\n",
      "metricas : 2 {'acc': 0.6791044776119403, 'prec': 0.6845210655582845, 'rec': 0.6791044776119403, 'spec': 0.7918735632183909, 'f1_score': 0.6781830087669398}\n",
      "Iteração número:  1\n"
     ]
    }
   ],
   "source": [
    "# Loop principal:  (cross_val )\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_ITER, random_state=None)\n",
    "\n",
    "# Split com rótulos Bethesda para um split estratificado (cada iteração executa todos os classificadores de 1 à 4)\n",
    "# Separa dados para treino/validação e teste:\n",
    "for it, (idx_train, idx_test) in enumerate(cv.split(data.values, target['bethesda'].values)):\n",
    "    print('Iteração número: ', it)\n",
    "\n",
    "    # Filtra apenas features selecionadas\n",
    "    X_train = data[best_features_spfsr_1].values[idx_train]\n",
    "    y_train = target['binary'].values[idx_train]\n",
    "    \n",
    "    X_test = data[best_features_spfsr_1].values[idx_test]\n",
    "    y_test = target['binary'].values[idx_test]\n",
    "                                                   \n",
    "    ## treino e teste dos modelo (classificador 1):\n",
    "    for i in range(3):   \n",
    "        ## Obtem modelo\n",
    "        model = getModel(params= params[i], classifier = classifiers[i], class_type = 'binary')\n",
    "        metr, model = fit_model(X_train, y_train, model, cls_type= 1)\n",
    "        # Predição:\n",
    "        pred_y = np.empty(len(idx_test)) \n",
    "        pred_y = model.predict(X_test)\n",
    "        prob_y = model.predict_proba(X_test)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_bin[idx_test, i] = pred_y\n",
    "        probs_bin[idx_test, i] = prob_y\n",
    "        \n",
    "        # Registra predições (classicações ternária/bethesda):\n",
    "        idx_0 = index_pred_from_class(idx_test, pred_y, cls=0)\n",
    "        preds_ter[idx_0, i] =  preds_bin[idx_0, i]\n",
    "        probs_ter[idx_0, i] =  probs_bin[idx_0, i] \n",
    "        preds_bet[idx_0, i] =  preds_bin[idx_0, i]\n",
    "        probs_bet[idx_0, i] =  probs_bin[idx_0, i]  \n",
    "        \n",
    "        #print('target_idx_:', target['ternary'].loc[idx_test])\n",
    "        #print('pred in bin:', preds_bin[idx_test, i])\n",
    "        #print('pred in ter:', preds_ter[idx_test, i])\n",
    "\n",
    "    ##------------ X ------------- \n",
    "    ## Classificador 2: lesões de alto/baixo grau\n",
    "    \n",
    "    ## Seleciona amostras para treino/teste\n",
    "    # Treino: seleciona apenas amostras do conjunto de treino para rótulos ternários 1 e 2, filtrando \n",
    "    # apenas features selecionadas para o classificador 2\n",
    "    X_df_train2, y_df_train2 = filter_dataXY(data[best_features_spfsr_2].loc[idx_train],\n",
    "                                       target.loc[idx_train], 2)\n",
    "    X_train2, y_train2 = X_df_train2.values,  y_df_train2.values\n",
    "        \n",
    "    for i in range(3):   \n",
    "        ## Obtem dados para teste de acordo com a predição de cada modelo do classificador 1\n",
    "        # Teste: filtra amostras de rótulos 1 das predições do classificador 1  \n",
    "        idx_test2, X_df_test2, y_df_test2 = filter_Xy_from_cls1_to_cls2(data[best_features_spfsr_2].loc[idx_test],\n",
    "                                                        target.loc[idx_test], preds_bin[:,i], idx_test)\n",
    "        \n",
    "        X_test2, y_test2= X_df_test2.values, y_df_test2.values\n",
    " \n",
    "        ## Obtem modelo\n",
    "        model = getModel(params= params[i], classifier = classifiers[i], class_type = 'binary')\n",
    "        metr, model = fit_model(X_train2, y_train2, model, cls_type= 2)\n",
    "        #print('metricas :', i, metr)\n",
    "        \n",
    "        # Predição:\n",
    "        pred2_y = np.empty(len(idx_test2))\n",
    "        pred2_y = model.predict(X_test2)\n",
    "        pred2_y = le_2.inverse_transform(pred2_y)\n",
    "        #prob_y = model.predict_proba(X_test2)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_ter[idx_test2, i] = pred2_y\n",
    "        #probs_ter[idx_test2, i] = prob_y\n",
    "        \n",
    "        \n",
    "    ##------------ X ------------- \n",
    "    ## Classificador 3: ASC-US/LSIL\n",
    "    \n",
    "    ## Seleciona amostras para treino/teste\n",
    "    # Treino: seleciona apenas amostras do conjunto de treino para rótulos bethesda 1 e 3, filtrando \n",
    "    # apenas features selecionadas para o classificador 3\n",
    "    X_df_train3, y_df_train3 = filter_dataXY(data[best_features_MI_3].loc[idx_train],\n",
    "                                       target.loc[idx_train], 3)\n",
    "    X_train3, y_train3 = X_df_train3.values,  y_df_train3.values\n",
    "    \n",
    "    \n",
    "    for i in range(3):   \n",
    "        ## Obtem dados para teste de acordo com a predição de cada modelo do classificador 2\n",
    "        # Filtra amostras de rótulos 1 (lesão de baixo grau) das predições dos classificadores 2  \n",
    "        idx_test3, X_df_test3, y_df_test3 = filter_Xy_from_cls1_to_cls3(data[best_features_MI_3].loc[idx_test],\n",
    "                                                        target.loc[idx_test], preds_ter[:,i], idx_test)\n",
    "        \n",
    "        X_test3, y_test3= X_df_test3.values, y_df_test3.values\n",
    " \n",
    "        ## Obtem modelo\n",
    "        model = getModel(params= params[i], classifier = classifiers[i], class_type = 'binary')\n",
    "        metr, model = fit_model(X_train3, y_train3, model, cls_type= 3)\n",
    "        #print('metricas :', i, metr)\n",
    "        \n",
    "        # Predição:\n",
    "        pred3_y = np.empty(len(idx_test3))\n",
    "        pred3_y = model.predict(X_test3)\n",
    "        pred3_y = le_3.inverse_transform(pred3_y)\n",
    "        #prob_y = model.predict_proba(X_test3)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_bet[idx_test3, i] = pred3_y\n",
    "        #probs_bet[idx_test3, i] = prob_y\n",
    "        \n",
    "    ##------------ X ------------- \n",
    "    ## Classificador 4: ASC-H/HSIL/Car\n",
    "    \n",
    "    ## Seleciona amostras para treino/teste\n",
    "    # Treino: seleciona apenas amostras do conjunto de treino para rótulos bethesda 2,4,5, filtrando \n",
    "    # apenas features selecionadas para o classificador 4\n",
    "    X_df_train4, y_df_train4 = filter_dataXY(data[best_features_MI_4].loc[idx_train],\n",
    "                                       target.loc[idx_train], 4)\n",
    "    X_train4, y_train4 = X_df_train4.values,  y_df_train4.values\n",
    "    \n",
    "    \n",
    "    for i in range(3):   \n",
    "        ## Obtem dados para teste de acordo com a predição de cada modelo do classificador 2\n",
    "        # Filtra amostras de rótulos 2(lesão de alto grau) das predições dos classificadores 2  \n",
    "        idx_test4, X_df_test4, y_df_test4 = filter_Xy_from_cls2_to_cls4(data[best_features_MI_4].loc[idx_test],\n",
    "                                                        target.loc[idx_test], preds_ter[:,i], idx_test)\n",
    "        \n",
    "        X_test4, y_test4= X_df_test4.values, y_df_test4.values\n",
    " \n",
    "        ## Obtem modelo\n",
    "        model = getModel(params= params[i], classifier = classifiers[i], class_type = 'ternary')\n",
    "        metr, model = fit_model(X_train4, y_train4, model, cls_type= 4)\n",
    "        print('metricas :', i, metr)\n",
    "        \n",
    "        # Predição:\n",
    "        pred4_y = np.empty(len(idx_test4))\n",
    "        pred4_y = model.predict(X_test4)\n",
    "        pred4_y = le_4.inverse_transform(pred4_y)\n",
    "        #prob_y = model.predict_proba(X_test4)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_bet[idx_test4, i] = pred4_y\n",
    "        #probs_bet[idx_test4, i] = prob_y\n",
    " \n",
    "## Resultados - classificação binária (normal/anormal):\n",
    "# Calcula curva_roc e AUC:\n",
    "for i in range(3):   \n",
    "    prob = probs_bin[:, i, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(target['binary'].values, prob)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    aucs[i]= auc(mean_fpr, interp_tpr)\n",
    "    labels_list_bin.append(r\"ROC Curve (AUC %s= %0.4f)\" % ((classifiers[i]+\"- normal/anormal\"), aucs[i]))\n",
    "    roc_curve_list_bin.append((mean_fpr, interp_tpr))\n",
    "    \n",
    "    # Calcula e registra métricas p/ fold:\n",
    "    accs[i] = calc_metric(target['binary'].values, preds_bin[:,i], metric_type='acc', class_type='binary', pos_label=1, classes=[0,1])\n",
    "    precs[i] = calc_metric(target['binary'].values, preds_bin[:,i], metric_type='prec',class_type='binary')                \n",
    "    recs[i] = calc_metric(target['binary'].values, preds_bin[:,i], metric_type='rec',class_type='binary')                \n",
    "    specs[i] = calc_metric(target['binary'].values, preds_bin[:,i], metric_type='spec',class_type='binary')                \n",
    "    f1_scores[i] = calc_metric(target['binary'].values, preds_bin[:,i], metric_type='f1_score',class_type='binary')        \n",
    "    # Acumula métricas no dataframe de resultados e agrupa curvas ROC para exibição:\n",
    "    metrics= {'Model': classifiers[i], 'acc': accs[i], 'prec': precs[i], 'rec': recs[i], \n",
    "              'spec': specs[i], 'f1_score': f1_scores[i], 'AUC': aucs[i]}                                      \n",
    "    fill_line_metrics_CV(classifiers[i], features_desc, i, metrics, results_bin, class_type='1- Normal/Anormal')            \n",
    "    # Acumula Matrizes de confusão:  https://stackoverflow.com/questions/61016110/plot-multiple-confusion-matrices-with-plot-confusion-matrix\n",
    "    preds_to_conf_matrix_bin.append((target['binary'].values, preds_bin[:,i], \"1. Normal/Anormal -\"+str(classifiers[i])))\n",
    "            \n",
    "  \n",
    "## Resultados - classificação ternária (normal/baixo grau/ alto grau)\n",
    "# Calcula métricas e matrix de confusão:\n",
    "for i in range(3):       \n",
    "    # Calcula e registra métricas p/ fold:\n",
    "    accs[i] = calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='acc', class_type='ternary', classes=[0,1,2])\n",
    "    precs[i] = calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='prec',class_type='ternary', classes=[0,1,2])                \n",
    "    recs[i] = calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='rec',class_type='ternary', classes=[0,1,2])                \n",
    "    specs[i] = calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='spec',class_type='ternary', classes=[0,1,2])                \n",
    "    f1_scores[i] = calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='f1_score',class_type='ternary', classes=[0,1,2])        \n",
    "    # Acumula métricas no dataframe de resultados e agrupa curvas ROC para exibição:\n",
    "    metrics= {'Model': classifiers[i], 'acc': accs[i], 'prec': precs[i], 'rec': recs[i], \n",
    "              'spec': specs[i], 'f1_score': f1_scores[i], 'AUC': aucs[i]}                                      \n",
    "    fill_line_metrics_CV(classifiers[i], features_desc, i, metrics, results_ter, class_type='2- Normal/Low G./High G.')            \n",
    "    # Acumula Matrizes de confusão:  https://stackoverflow.com/questions/61016110/plot-multiple-confusion-matrices-with-plot-confusion-matrix\n",
    "    preds_to_conf_matrix_ter.append((target['ternary'].values, preds_ter[:,i], \"2- Normal/Low G./High G. -\"+str(classifiers[i])))\n",
    "\n",
    "    \n",
    "## Resultados - classificação bethesda (normal/ascus/asch/lsil/hsil/car)\n",
    "# Calcula métricas e matrix de confusão:\n",
    "for i in range(3):   \n",
    "    # Calcula e registra métricas p/ fold:\n",
    "    accs[i] = calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='acc', class_type='bethesda', classes=[0,1,2,3,4,5])\n",
    "    precs[i] = calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='prec',class_type='bethesda', classes=[0,1,2,3,4,5])                \n",
    "    recs[i] = calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='rec',class_type='bethesda', classes=[0,1,2,3,4,5])                \n",
    "    specs[i] = calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='spec',class_type='bethesda', classes=[0,1,2,3,4,5])                \n",
    "    f1_scores[i] = calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='f1_score',class_type='bethesda', classes=[0,1,2,3,4,5])        \n",
    "    # Acumula métricas no dataframe de resultados e agrupa curvas ROC para exibição:\n",
    "    metrics= {'Model': classifiers[i], 'acc': accs[i], 'prec': precs[i], 'rec': recs[i], \n",
    "              'spec': specs[i], 'f1_score': f1_scores[i], 'AUC': aucs[i]}                                      \n",
    "    fill_line_metrics_CV(classifiers[i], features_desc, i, metrics, results_bet, class_type='3- Bethesda')            \n",
    "    # Acumula Matrizes de confusão:  https://stackoverflow.com/questions/61016110/plot-multiple-confusion-matrices-with-plot-confusion-matrix\n",
    "    preds_to_conf_matrix_bet.append((target['bethesda'].values, preds_bet[:,i], \"3- Bethesda -\"+str(classifiers[i])))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe curvas roc, matrizes de confusão e métricas - Classificador binário:\n",
    "plot_roc_curve_CV(roc_curve_list_bin, labels_list_bin, title = \"ROC Curve - 1.Normal/Anormal\")\n",
    "plot_conf_matrix(preds_to_conf_matrix_bin, lbls=[0,1], disp_lbls=['normal', 'anormal'])\n",
    "results_bin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe matrizes de confusão e métricas - Classificador ternário:\n",
    "plot_conf_matrix(preds_to_conf_matrix_ter, lbls=[0,1,2], disp_lbls=['normal','low g.', 'high g.'])\n",
    "results_ter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe matrizes de confusão e métricas - Classificador ternário:\n",
    "plot_conf_matrix(preds_to_conf_matrix_bet, lbls=[0,1,2,3,4,5], disp_lbls=['normal','ascus', 'asch', 'lsil', 'hsil', 'car'])\n",
    "results_bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa518ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
