{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b43ab41",
   "metadata": {},
   "source": [
    "## Classificador hierárquico para características morfométricas de núcleo de células cervicais (sem EFD's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd46ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from math import sqrt\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow \n",
    "from skimage import morphology, measure\n",
    "from skimage.draw import polygon, polygon_perimeter\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "import pyefd\n",
    "from pyefd import elliptic_fourier_descriptors, normalize_efd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# pay attention to capitalization below!\n",
    "from spFSR import SpFSR\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE, BorderlineSMOTE\n",
    "\n",
    "from itertools import cycle\n",
    "from random import randint\n",
    "from random import sample\n",
    "\n",
    "import xgboost as xgb \n",
    "\n",
    "import functions, shapeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b5ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bethesda_classes = {'Normal':0, 'ASC-US':1, 'ASC-H':2, 'LSIL':3,'HSIL':4, 'Invasive Carcinoma':5} \n",
    "Bethesda_idx_classes = {0: 'Normal', 1:'ASC-US', 2:'ASC-H', 3:'LSIL',4: 'HSIL', 5:'Invasive Carcinoma'} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b81cb",
   "metadata": {},
   "source": [
    "### Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4457980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 98, 98, 154)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(functions.list_all_features(20)), len(functions.list_all_nucleus_features(20)), len(functions.list_all_cyto_features(20)), len(functions.list_all_EFD_features(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f815eb",
   "metadata": {},
   "source": [
    "### Lê arquivo (features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f00307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EFD_COEFFS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2400f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataCRIC.csv', sep='|', header=0)\n",
    "df = shapeFeatures.normalize_dataset(df, n_efd_coeffs= N_EFD_COEFFS)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c0dc99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>areaN</th>\n",
       "      <th>eccenN</th>\n",
       "      <th>extentN</th>\n",
       "      <th>periN</th>\n",
       "      <th>maxAxN</th>\n",
       "      <th>minAxN</th>\n",
       "      <th>compacN</th>\n",
       "      <th>circuN</th>\n",
       "      <th>...</th>\n",
       "      <th>efdC73</th>\n",
       "      <th>efdC74</th>\n",
       "      <th>efdC75</th>\n",
       "      <th>efdC76</th>\n",
       "      <th>efdC77</th>\n",
       "      <th>ratio_NC</th>\n",
       "      <th>ratio_NC_per</th>\n",
       "      <th>ratio_NC_hArea</th>\n",
       "      <th>nucleus_position</th>\n",
       "      <th>bethesda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14796.0</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.606414</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>0.031326</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>0.083827</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>0.863522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156532</td>\n",
       "      <td>0.321490</td>\n",
       "      <td>0.859931</td>\n",
       "      <td>0.382225</td>\n",
       "      <td>0.302311</td>\n",
       "      <td>0.017236</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.099098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.541484</td>\n",
       "      <td>0.808102</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>0.039493</td>\n",
       "      <td>0.095649</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150931</td>\n",
       "      <td>0.317850</td>\n",
       "      <td>0.859539</td>\n",
       "      <td>0.369221</td>\n",
       "      <td>0.299938</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.089517</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.121456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14798.0</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.313794</td>\n",
       "      <td>0.884418</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.097062</td>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.890378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153458</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.861978</td>\n",
       "      <td>0.367980</td>\n",
       "      <td>0.302076</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.073961</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.043773</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14799.0</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.489270</td>\n",
       "      <td>0.778201</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.103428</td>\n",
       "      <td>0.021001</td>\n",
       "      <td>0.879403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.319562</td>\n",
       "      <td>0.860312</td>\n",
       "      <td>0.382943</td>\n",
       "      <td>0.303682</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>0.154784</td>\n",
       "      <td>0.027752</td>\n",
       "      <td>0.128927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14801.0</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>0.036826</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.106376</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.861871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147193</td>\n",
       "      <td>0.314554</td>\n",
       "      <td>0.860292</td>\n",
       "      <td>0.359672</td>\n",
       "      <td>0.300094</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.129992</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>0.069245</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>399.0</td>\n",
       "      <td>11539.0</td>\n",
       "      <td>0.028927</td>\n",
       "      <td>0.838629</td>\n",
       "      <td>0.579720</td>\n",
       "      <td>0.094256</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.118369</td>\n",
       "      <td>0.041270</td>\n",
       "      <td>0.784196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152113</td>\n",
       "      <td>0.318217</td>\n",
       "      <td>0.859606</td>\n",
       "      <td>0.370535</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.206211</td>\n",
       "      <td>0.149094</td>\n",
       "      <td>0.085315</td>\n",
       "      <td>1.943974</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>399.0</td>\n",
       "      <td>11540.0</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.874227</td>\n",
       "      <td>0.645532</td>\n",
       "      <td>0.094611</td>\n",
       "      <td>0.135676</td>\n",
       "      <td>0.100778</td>\n",
       "      <td>0.064959</td>\n",
       "      <td>0.692461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150010</td>\n",
       "      <td>0.322108</td>\n",
       "      <td>0.859366</td>\n",
       "      <td>0.375599</td>\n",
       "      <td>0.300755</td>\n",
       "      <td>0.245537</td>\n",
       "      <td>0.247086</td>\n",
       "      <td>0.136756</td>\n",
       "      <td>0.916374</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>400.0</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>0.017031</td>\n",
       "      <td>0.910741</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.092280</td>\n",
       "      <td>0.136377</td>\n",
       "      <td>0.078990</td>\n",
       "      <td>0.131860</td>\n",
       "      <td>0.507358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>0.319972</td>\n",
       "      <td>0.860379</td>\n",
       "      <td>0.372458</td>\n",
       "      <td>0.303245</td>\n",
       "      <td>0.191508</td>\n",
       "      <td>0.471092</td>\n",
       "      <td>0.188343</td>\n",
       "      <td>0.326252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>400.0</td>\n",
       "      <td>11536.0</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.949322</td>\n",
       "      <td>0.528816</td>\n",
       "      <td>0.105709</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>0.065965</td>\n",
       "      <td>0.137720</td>\n",
       "      <td>0.494794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151898</td>\n",
       "      <td>0.320620</td>\n",
       "      <td>0.859608</td>\n",
       "      <td>0.370771</td>\n",
       "      <td>0.299599</td>\n",
       "      <td>0.111823</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>0.023058</td>\n",
       "      <td>3.177247</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>400.0</td>\n",
       "      <td>11537.0</td>\n",
       "      <td>0.025076</td>\n",
       "      <td>0.822746</td>\n",
       "      <td>0.749691</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>0.120781</td>\n",
       "      <td>0.114052</td>\n",
       "      <td>0.055801</td>\n",
       "      <td>0.725789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143373</td>\n",
       "      <td>0.318753</td>\n",
       "      <td>0.868085</td>\n",
       "      <td>0.362569</td>\n",
       "      <td>0.279162</td>\n",
       "      <td>0.448090</td>\n",
       "      <td>0.346307</td>\n",
       "      <td>0.181780</td>\n",
       "      <td>0.653692</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3233 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  cell_id     areaN    eccenN   extentN     periN    maxAxN  \\\n",
       "0          1.0  14796.0  0.007403  0.606414  0.842276  0.031326  0.036711   \n",
       "1          1.0  14797.0  0.009371  0.541484  0.808102  0.035945  0.039493   \n",
       "2          1.0  14798.0  0.007275  0.313794  0.884418  0.029457  0.025365   \n",
       "3          1.0  14799.0  0.010570  0.489270  0.778201  0.040199  0.040900   \n",
       "4          1.0  14801.0  0.009115  0.296366  0.842276  0.036826  0.031283   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "3228     399.0  11539.0  0.028927  0.838629  0.579720  0.094256  0.134656   \n",
       "3229     399.0  11540.0  0.025333  0.874227  0.645532  0.094611  0.135676   \n",
       "3230     400.0  11535.0  0.017031  0.910741  0.390863  0.092280  0.136377   \n",
       "3231     400.0  11536.0  0.020797  0.949322  0.528816  0.105709  0.169029   \n",
       "3232     400.0  11537.0  0.025076  0.822746  0.749691  0.090669  0.120781   \n",
       "\n",
       "        minAxN   compacN    circuN  ...    efdC73    efdC74    efdC75  \\\n",
       "0     0.083827  0.024126  0.863522  ...  0.156532  0.321490  0.859931   \n",
       "1     0.095649  0.018763  0.891071  ...  0.150931  0.317850  0.859539   \n",
       "2     0.097062  0.018895  0.890378  ...  0.153458  0.315454  0.861978   \n",
       "3     0.103428  0.021001  0.879403  ...  0.157254  0.319562  0.860312   \n",
       "4     0.106376  0.024456  0.861871  ...  0.147193  0.314554  0.860292   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3228  0.118369  0.041270  0.784196  ...  0.152113  0.318217  0.859606   \n",
       "3229  0.100778  0.064959  0.692461  ...  0.150010  0.322108  0.859366   \n",
       "3230  0.078990  0.131860  0.507358  ...  0.153944  0.319972  0.860379   \n",
       "3231  0.065965  0.137720  0.494794  ...  0.151898  0.320620  0.859608   \n",
       "3232  0.114052  0.055801  0.725789  ...  0.143373  0.318753  0.868085   \n",
       "\n",
       "        efdC76    efdC77  ratio_NC  ratio_NC_per  ratio_NC_hArea  \\\n",
       "0     0.382225  0.302311  0.017236      0.115646        0.016730   \n",
       "1     0.369221  0.299938  0.010656      0.089517        0.010168   \n",
       "2     0.367980  0.302076  0.007400      0.073961        0.006897   \n",
       "3     0.382943  0.303682  0.028309      0.154784        0.027752   \n",
       "4     0.359672  0.300094  0.021569      0.129992        0.020738   \n",
       "...        ...       ...       ...           ...             ...   \n",
       "3228  0.370535  0.299400  0.206211      0.149094        0.085315   \n",
       "3229  0.375599  0.300755  0.245537      0.247086        0.136756   \n",
       "3230  0.372458  0.303245  0.191508      0.471092        0.188343   \n",
       "3231  0.370771  0.299599  0.111823      0.078186        0.023058   \n",
       "3232  0.362569  0.279162  0.448090      0.346307        0.181780   \n",
       "\n",
       "      nucleus_position  bethesda  \n",
       "0             0.099098       0.0  \n",
       "1             0.121456       0.0  \n",
       "2             0.043773       0.0  \n",
       "3             0.128927       0.0  \n",
       "4             0.069245       0.0  \n",
       "...                ...       ...  \n",
       "3228          1.943974       5.0  \n",
       "3229          0.916374       5.0  \n",
       "3230          0.326252       5.0  \n",
       "3231          3.177247       5.0  \n",
       "3232          0.653692       5.0  \n",
       "\n",
       "[3233 rows x 203 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581d6797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Totais por classe --- \n",
      "Normal...:  862\n",
      "ASC-Us...:  286\n",
      "ASC-H....:  536\n",
      "LSIL.....:  598\n",
      "HSIL.....:  874\n",
      "Carcinoma:  77\n"
     ]
    }
   ],
   "source": [
    "# Separa dados por classe de maneira balanceada:\n",
    "data_normal = df[df['bethesda'] == 0].copy()\n",
    "data_normal.set_index((i for i in range(data_normal.shape[0])), inplace=True)\n",
    "\n",
    "data_ascus = df[df['bethesda'] == 1].copy()\n",
    "data_ascus.set_index((i for i in range(data_ascus.shape[0])), inplace=True)\n",
    "\n",
    "data_asch = df[df['bethesda'] == 2].copy()\n",
    "data_asch.set_index((i for i in range(data_asch.shape[0])), inplace=True)\n",
    "\n",
    "data_lsil = df[df['bethesda'] == 3].copy()\n",
    "data_lsil.set_index((i for i in range(data_lsil.shape[0])), inplace=True)\n",
    "\n",
    "data_hsil = df[df['bethesda'] == 4].copy()\n",
    "data_hsil.set_index((i for i in range(data_hsil.shape[0])), inplace=True)\n",
    "\n",
    "data_car = df[df['bethesda'] == 5].copy()\n",
    "data_car.set_index((i for i in range(data_car.shape[0])), inplace=True)\n",
    "\n",
    "print(\"--- Totais por classe --- \")               \n",
    "print(\"Normal...: \", data_normal.values.shape[0])               \n",
    "print(\"ASC-Us...: \", data_ascus.values.shape[0])               \n",
    "print(\"ASC-H....: \", data_asch.values.shape[0])               \n",
    "print(\"LSIL.....: \", data_lsil.values.shape[0])               \n",
    "print(\"HSIL.....: \", data_hsil.values.shape[0])               \n",
    "print(\"Carcinoma: \", data_car.values.shape[0]) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3e8af",
   "metadata": {},
   "source": [
    "#### Gera dataframes: dados (data), classes (target) e Ids (image/cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56929844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monta base (data, target, image/cells ids)\n",
    "data, target, image_cells_ids= functions.get_database_data_targe_ids(data_normal, data_ascus, \n",
    "                       data_lsil, data_asch, data_hsil,data_car,\n",
    "                       functions.list_all_features(N_EFD_COEFFS))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02587fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parâmetros resultantes de gridsearch dos modelos (tuning.ipynb)\n",
    "svm_param =  {'C': 100, 'kernel': 'linear'}\n",
    "rf_param = {'max_depth': 7, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "xgb_param = {'learning_rate': 0.1, 'n_estimators': 86, 'max_depth': 9, 'min_child_weight':1,\n",
    "              'gamma':0, 'subsample':0.9, 'colsample_bytree':0.7, 'reg_alpha': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26b7c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº total de de features: 21\n"
     ]
    }
   ],
   "source": [
    "classifiers = ['SVM', 'RF', 'XGBoost']\n",
    "params = [svm_param, rf_param, xgb_param]\n",
    "features = functions.list_all_nucleus_without_EFD() \n",
    "print(f'Nº total de de features: {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91d5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Features resultantes seleção prévia (Vide arquivos <features_selection>.ipynb)\n",
    "\n",
    "best_features_spfsr_1= best_features_spfsr_2= best_features_spfsr_3= best_features_spfsr_4= features\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "513173bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21, 21, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_features_spfsr_1), len(best_features_spfsr_2), len(best_features_spfsr_3), len(best_features_spfsr_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da6443",
   "metadata": {},
   "source": [
    "## Experiment nº5:   nucleus  without EFD features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e110ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_desc = \"All features of nucleus without EFD features\"\n",
    "N_ITER = 10\n",
    " \n",
    "accs = precs = recs = specs = f1_scores = aucs = np.zeros((3))\n",
    "\n",
    "labels_list_bin = [] \n",
    "roc_curve_list_bin = []\n",
    "\n",
    "preds_to_conf_matrix_bin= []\n",
    "preds_to_conf_matrix_ter= []\n",
    "preds_to_conf_matrix_bet= []\n",
    "\n",
    "results_bin = pd.DataFrame(columns=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , 'Falso Pos', 'Especif', 'F1_measure'])\n",
    "results_ter = pd.DataFrame(columns=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , 'Falso Pos', 'Especif', 'F1_measure'])\n",
    "results_bet = pd.DataFrame(columns=['Tipo', 'Model', 'Features', 'Acurácia', 'Precisão', 'Sensibil' , 'Falso Pos', 'Especif', 'F1_measure'])\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39014f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara array para registro de predições (classific. binário, ternário e bethesda) separado por algoritmos:\n",
    "preds_bin = np.ones((data.shape[0],3))*-1\n",
    "probs_bin = np.zeros((data.shape[0],3,2))\n",
    " \n",
    "preds_ter = np.ones((data.shape[0],3))*-1\n",
    "probs_ter = np.zeros((data.shape[0],3,2))\n",
    "\n",
    "preds_bet = np.ones((data.shape[0],3))*-1\n",
    "probs_bet = np.zeros((data.shape[0],3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9141ee28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_2 = preprocessing.LabelEncoder()\n",
    "le_2.fit([1,2])\n",
    "le_3 = preprocessing.LabelEncoder()\n",
    "le_3.fit([1,3])\n",
    "le_4 = preprocessing.LabelEncoder()\n",
    "le_4.fit([2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7ad6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração número:  0\n"
     ]
    }
   ],
   "source": [
    "# Loop principal:  (cross_val )\n",
    "start_t = functions.timer()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_ITER, random_state=None)\n",
    "\n",
    "# Split com rótulos Bethesda para um split estratificado (cada iteração executa todos os classificadores de 1 à 4)\n",
    "# Separa dados para treino/validação e teste:\n",
    "for it, (idx_train, idx_test) in enumerate(cv.split(data.values, target['bethesda'].values)):\n",
    "    print('Iteração número: ', it)\n",
    "\n",
    "    # Filtra apenas features selecionadas\n",
    "    X_train = data[best_features_spfsr_1].values[idx_train]\n",
    "    y_train = target['binary'].values[idx_train]\n",
    "    \n",
    "    X_test = data[best_features_spfsr_1].values[idx_test]\n",
    "    y_test = target['binary'].values[idx_test]\n",
    "                                                   \n",
    "    ## treino e teste dos modelo (classificador 1):\n",
    "    for i in range(3):   \n",
    "        ## Obtem modelo\n",
    "        model = functions.getModel(params= params[i], classifier = classifiers[i], class_type = 'binary')\n",
    "        metr, model = functions.fit_model(X_train, y_train, model, cls_type= 1)\n",
    "        # Predição:\n",
    "        pred_y = np.empty(len(idx_test)) \n",
    "        pred_y = model.predict(X_test)\n",
    "        prob_y = model.predict_proba(X_test)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_bin[idx_test, i] = pred_y\n",
    "        probs_bin[idx_test, i] = prob_y\n",
    "        \n",
    "        # Registra predições (classicações ternária/bethesda):\n",
    "        idx_0 = functions.index_pred_from_class(idx_test, pred_y, cls=0)\n",
    "        preds_ter[idx_0, i] =  preds_bin[idx_0, i]\n",
    "        probs_ter[idx_0, i] =  probs_bin[idx_0, i] \n",
    "        preds_bet[idx_0, i] =  preds_bin[idx_0, i]\n",
    "        probs_bet[idx_0, i] =  probs_bin[idx_0, i]  \n",
    "\n",
    "    ##------------ X ------------- \n",
    "    ## Classificador 2: lesões de alto/baixo grau\n",
    "    \n",
    "    ## Seleciona amostras para treino/teste\n",
    "    # Treino: seleciona apenas amostras do conjunto de treino para rótulos ternários 1 e 2, filtrando \n",
    "    # apenas features selecionadas para o classificador 2\n",
    "    X_df_train2, y_df_train2 = functions.filter_dataXY(data[best_features_spfsr_2].loc[idx_train],\n",
    "                                       target.loc[idx_train], 2)\n",
    "    X_train2, y_train2 = X_df_train2.values,  y_df_train2.values\n",
    "        \n",
    "    for i in range(3):   \n",
    "        ## Obtem dados para teste de acordo com a predição de cada modelo do classificador 1\n",
    "        # Teste: filtra amostras de rótulos 1 das predições do classificador 1  \n",
    "        idx_test2, X_df_test2, y_df_test2 = functions.filter_Xy_from_cls1_to_cls2(data[best_features_spfsr_2].loc[idx_test],\n",
    "                                                        target.loc[idx_test], preds_bin[:,i], idx_test)\n",
    "        \n",
    "        X_test2, y_test2= X_df_test2.values, y_df_test2.values\n",
    " \n",
    "        ## Obtem modelo\n",
    "        model = functions.getModel(params= params[i], classifier = classifiers[i], class_type = 'binary')\n",
    "        metr, model = functions.fit_model(X_train2, y_train2, model, cls_type= 2)\n",
    "        #print('metricas :', i, metr)\n",
    "        \n",
    "        # Predição:\n",
    "        pred2_y = np.empty(len(idx_test2))\n",
    "        pred2_y = model.predict(X_test2)\n",
    "        pred2_y = le_2.inverse_transform(pred2_y)\n",
    "        #prob_y = model.predict_proba(X_test2)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_ter[idx_test2, i] = pred2_y\n",
    "        #probs_ter[idx_test2, i] = prob_y        \n",
    "        \n",
    "    ##------------ X ------------- \n",
    "    ## Classificador 3: ASC-US/LSIL\n",
    "    \n",
    "    ## Seleciona amostras para treino/teste\n",
    "    # Treino: seleciona apenas amostras do conjunto de treino para rótulos bethesda 1 e 3, filtrando \n",
    "    # apenas features selecionadas para o classificador 3\n",
    "    X_df_train3, y_df_train3 = functions.filter_dataXY(data[best_features_spfsr_3].loc[idx_train],\n",
    "                                       target.loc[idx_train], 3)\n",
    "    X_train3, y_train3 = X_df_train3.values,  y_df_train3.values\n",
    "    \n",
    "    for i in range(3):   \n",
    "        ## Obtem dados para teste de acordo com a predição de cada modelo do classificador 2\n",
    "        # Filtra amostras de rótulos 1 (lesão de baixo grau) das predições dos classificadores 2  \n",
    "        idx_test3, X_df_test3, y_df_test3 = functions.filter_Xy_from_cls1_to_cls3(data[best_features_spfsr_3].loc[idx_test],\n",
    "                                                        target.loc[idx_test], preds_ter[:,i], idx_test)\n",
    "        \n",
    "        X_test3, y_test3= X_df_test3.values, y_df_test3.values\n",
    " \n",
    "        ## Obtem modelo\n",
    "        model = functions.getModel(params= params[i], classifier = classifiers[i], class_type = 'binary')\n",
    "        metr, model = functions.fit_model(X_train3, y_train3, model, cls_type= 3)\n",
    "        #print('--metricas Classificador 3 :', i, metr)\n",
    "        \n",
    "        # Predição:\n",
    "        pred3_y = np.empty(len(idx_test3))\n",
    "        pred3_y = model.predict(X_test3)\n",
    "        pred3_y = le_3.inverse_transform(pred3_y)\n",
    "        #prob_y = model.predict_proba(X_test3)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_bet[idx_test3, i] = pred3_y\n",
    "        #probs_bet[idx_test3, i] = prob_y\n",
    "        \n",
    "    ##------------ X ------------- \n",
    "    ## Classificador 4: ASC-H/HSIL/Car\n",
    "    \n",
    "    ## Seleciona amostras para treino/teste\n",
    "    # Treino: seleciona apenas amostras do conjunto de treino para rótulos bethesda 2,4,5, filtrando \n",
    "    # apenas features selecionadas para o classificador 4\n",
    "    X_df_train4, y_df_train4 = functions.filter_dataXY(data[best_features_spfsr_4].loc[idx_train],\n",
    "                                       target.loc[idx_train], 4)\n",
    "    X_train4, y_train4 = X_df_train4.values,  y_df_train4.values\n",
    "    \n",
    "    \n",
    "    for i in range(3):   \n",
    "        ## Obtem dados para teste de acordo com a predição de cada modelo do classificador 2\n",
    "        # Filtra amostras de rótulos 2(lesão de alto grau) das predições dos classificadores 2  \n",
    "        idx_test4, X_df_test4, y_df_test4 = functions.filter_Xy_from_cls2_to_cls4(data[best_features_spfsr_4].loc[idx_test],\n",
    "                                                        target.loc[idx_test], preds_ter[:,i], idx_test)\n",
    "        \n",
    "        X_test4, y_test4= X_df_test4.values, y_df_test4.values\n",
    " \n",
    "        ## Obtem modelo\n",
    "        model = functions.getModel(params= params[i], classifier = classifiers[i], class_type = 'ternary')\n",
    "        metr, model = functions.fit_model(X_train4, y_train4, model, cls_type= 4)\n",
    "        #print('metricas :', i, metr)\n",
    "        \n",
    "        # Predição:\n",
    "        pred4_y = np.empty(len(idx_test4))\n",
    "        pred4_y = model.predict(X_test4)\n",
    "        pred4_y = le_4.inverse_transform(pred4_y)\n",
    "        #prob_y = model.predict_proba(X_test4)\n",
    "\n",
    "        # Registra predições:\n",
    "        preds_bet[idx_test4, i] = pred4_y\n",
    "        #probs_bet[idx_test4, i] = prob_y\n",
    " \n",
    "## Resultados - classificação binária (normal/anormal):\n",
    "# Calcula curva_roc e AUC:\n",
    "for i in range(3):   \n",
    "    prob = probs_bin[:, i, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(target['binary'].values, prob)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    aucs[i]= auc(mean_fpr, interp_tpr)\n",
    "    labels_list_bin.append(r\"ROC Curve (AUC %s= %0.4f)\" % ((classifiers[i]+\"- normal/anormal\"), aucs[i]))\n",
    "    roc_curve_list_bin.append((mean_fpr, interp_tpr))\n",
    "    \n",
    "    # Calcula e registra métricas p/ fold:\n",
    "    accs[i] = functions.calc_metric(target['binary'].values, preds_bin[:,i], metric_type='acc', class_type='binary', pos_label=1, classes=[0,1])\n",
    "    precs[i] = functions.calc_metric(target['binary'].values, preds_bin[:,i], metric_type='prec',class_type='binary')                \n",
    "    recs[i] = functions.calc_metric(target['binary'].values, preds_bin[:,i], metric_type='rec',class_type='binary')                \n",
    "    specs[i] = functions.calc_metric(target['binary'].values, preds_bin[:,i], metric_type='spec',class_type='binary')                \n",
    "    f1_scores[i] = functions.calc_metric(target['binary'].values, preds_bin[:,i], metric_type='f1_score',class_type='binary')        \n",
    "    # Acumula métricas no dataframe de resultados e agrupa curvas ROC para exibição:\n",
    "    metrics= {'Model': classifiers[i], 'acc': accs[i], 'prec': precs[i], 'rec': recs[i], \n",
    "              'spec': specs[i], 'f1_score': f1_scores[i], 'AUC': aucs[i]}                                      \n",
    "    functions.fill_line_metrics_CV(classifiers[i], features_desc, i, metrics, results_bin, class_type='1- Normal/Anormal')            \n",
    "    # Acumula Matrizes de confusão:  https://stackoverflow.com/questions/61016110/plot-multiple-confusion-matrices-with-plot-confusion-matrix\n",
    "    preds_to_conf_matrix_bin.append((target['binary'].values, preds_bin[:,i], \"1. Normal/Anormal -\"+str(classifiers[i])))\n",
    "            \n",
    "  \n",
    "## Resultados - classificação ternária (normal/baixo grau/ alto grau)\n",
    "# Calcula métricas e matrix de confusão:\n",
    "for i in range(3):       \n",
    "    # Calcula e registra métricas p/ fold:\n",
    "    accs[i] = functions.calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='acc', class_type='ternary', classes=[0,1,2])\n",
    "    precs[i] = functions.calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='prec',class_type='ternary', classes=[0,1,2])                \n",
    "    recs[i] = functions.calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='rec',class_type='ternary', classes=[0,1,2])                \n",
    "    specs[i] = functions.calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='spec',class_type='ternary', classes=[0,1,2])                \n",
    "    f1_scores[i] = functions.calc_metric(target['ternary'].values, preds_ter[:,i], metric_type='f1_score',class_type='ternary', classes=[0,1,2])        \n",
    "    # Acumula métricas no dataframe de resultados e agrupa curvas ROC para exibição:\n",
    "    metrics= {'Model': classifiers[i], 'acc': accs[i], 'prec': precs[i], 'rec': recs[i], \n",
    "              'spec': specs[i], 'f1_score': f1_scores[i], 'AUC': aucs[i]}                                      \n",
    "    functions.fill_line_metrics_CV(classifiers[i], features_desc, i, metrics, results_ter, class_type='2- Normal/Low G./High G.')            \n",
    "    # Acumula Matrizes de confusão:  https://stackoverflow.com/questions/61016110/plot-multiple-confusion-matrices-with-plot-confusion-matrix\n",
    "    preds_to_conf_matrix_ter.append((target['ternary'].values, preds_ter[:,i], \"2- Normal/Low G./High G. -\"+str(classifiers[i])))\n",
    "\n",
    "    \n",
    "## Resultados - classificação bethesda (normal/ascus/asch/lsil/hsil/car)\n",
    "# Calcula métricas e matrix de confusão:\n",
    "for i in range(3):   \n",
    "    # Calcula e registra métricas p/ fold:\n",
    "    accs[i] = functions.calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='acc', class_type='bethesda', classes=[0,1,2,3,4,5])\n",
    "    precs[i] = functions.calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='prec',class_type='bethesda', classes=[0,1,2,3,4,5])                \n",
    "    recs[i] = functions.calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='rec',class_type='bethesda', classes=[0,1,2,3,4,5])                \n",
    "    specs[i] = functions.calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='spec',class_type='bethesda', classes=[0,1,2,3,4,5])                \n",
    "    f1_scores[i] = functions.calc_metric(target['bethesda'].values, preds_bet[:,i], metric_type='f1_score',class_type='bethesda', classes=[0,1,2,3,4,5])        \n",
    "    # Acumula métricas no dataframe de resultados e agrupa curvas ROC para exibição:\n",
    "    metrics= {'Model': classifiers[i], 'acc': accs[i], 'prec': precs[i], 'rec': recs[i], \n",
    "              'spec': specs[i], 'f1_score': f1_scores[i], 'AUC': aucs[i]}                                      \n",
    "    functions.fill_line_metrics_CV(classifiers[i], features_desc, i, metrics, results_bet, class_type='3- Bethesda')            \n",
    "    # Acumula Matrizes de confusão:  https://stackoverflow.com/questions/61016110/plot-multiple-confusion-matrices-with-plot-confusion-matrix\n",
    "    preds_to_conf_matrix_bet.append((target['bethesda'].values, preds_bet[:,i], \"3- Bethesda -\"+str(classifiers[i])))\n",
    "   \n",
    "functions.timer(start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe curvas roc, matrizes de confusão e métricas - Classificador binário:\n",
    "functions.plot_roc_curve_CV(roc_curve_list_bin, labels_list_bin, title = \"ROC Curve - 1.Normal/Anormal\")\n",
    "functions.plot_conf_matrix(preds_to_conf_matrix_bin, lbls=[0,1], disp_lbls=['normal', 'anormal'])\n",
    "results_bin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe matrizes de confusão e métricas - Classificador ternário:\n",
    "functions.plot_conf_matrix(preds_to_conf_matrix_ter, lbls=[0,1,2], disp_lbls=['normal','low g.', 'high g.'])\n",
    "results_ter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddbb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe matrizes de confusão e métricas - Classificador ternário:\n",
    "functions.plot_conf_matrix(preds_to_conf_matrix_bet, lbls=[0,1,2,3,4,5], disp_lbls=['normal','ascus', 'asch', 'lsil', 'hsil', 'car'])\n",
    "results_bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21bef70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
